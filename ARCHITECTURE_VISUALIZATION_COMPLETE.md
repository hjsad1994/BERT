# âœ… HOÃ€N THÃ€NH: Visualization Kiáº¿n trÃºc Model

## ğŸ¯ CÃ‚U Há»I:
> "Visual mÃ´ hÃ¬nh ViSoBERT káº¿t há»£p vá»›i Focal Loss vÃ  Contrastive Loss"
> "2 loss nÃ y cháº¡y cÃ¹ng lÃºc hay riÃªng láº»? Focal trÆ°á»›c hay Contrastive trÆ°á»›c?"

---

## âœ… TRáº¢ Lá»œI NGáº®N Gá»ŒN:

### **CHáº Y CÃ™NG LÃšC (SIMULTANEOUSLY)!**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1 FORWARD PASS                    â”‚
â”‚  â†“                                 â”‚
â”‚  ViSoBERT Encoder                  â”‚
â”‚  â†“                                 â”‚
â”‚  â”œâ”€â†’ Logits â†’ FOCAL LOSS          â”‚  â† PARALLEL
â”‚  â””â”€â†’ Embeddings â†’ CONTRASTIVE     â”‚
â”‚                                    â”‚
â”‚  Combine: 0.8*Focal + 0.2*Contr   â”‚
â”‚  â†“                                 â”‚
â”‚  1 BACKPROP (update all)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**KHÃ”NG PHáº¢I:**
- âŒ Focal trÆ°á»›c, rá»“i Contrastive
- âŒ 2 forward passes riÃªng láº»
- âŒ 2 backprops riÃªng láº»

**MÃ€ LÃ€:**
- âœ… 1 forward â†’ 2 outputs cÃ¹ng lÃºc
- âœ… 2 losses tÃ­nh cÃ¹ng lÃºc
- âœ… Combine â†’ 1 backprop

---

## ğŸ“Š FILES ÄÃƒ Táº O:

### **1. Visualizations (PNG)**

#### **`model_architecture.png`** (226KB)
- Kiáº¿n trÃºc model Ä‘áº§y Ä‘á»§
- Input â†’ Encoder â†’ 2 branches â†’ 2 losses â†’ Combine â†’ Backprop
- Color-coded cho tá»«ng component

#### **`forward_pass_timeline.png`** (222KB)
- Timeline step-by-step
- Shows PARALLEL execution
- Timing info (~70ms per batch)

#### **`sequential_vs_parallel.png`** (113KB)
- So sÃ¡nh WRONG vs CORRECT
- Sequential (sai) vs Parallel (Ä‘Ãºng)
- Why parallel is better

### **2. Documentation**

#### **`MODEL_ARCHITECTURE_EXPLAINED.md`**
- Giáº£i thÃ­ch chi tiáº¿t tá»«ng bÆ°á»›c
- Code examples
- Timeline vá»›i timing
- Q&A comprehensive

#### **`visualize_model_architecture.py`**
- Script táº¡o visualizations
- 3 functions: architecture, timeline, comparison
- CÃ³ thá»ƒ re-run báº¥t cá»© lÃºc nÃ o

---

## ğŸš€ XEM VISUALIZATIONS:

### **Quick Look:**
```bash
# Má»Ÿ file PNG:
start model_architecture.png
start forward_pass_timeline.png
start sequential_vs_parallel.png
```

### **Re-generate (náº¿u cáº§n):**
```bash
python visualize_model_architecture.py
```

---

## ğŸ“‹ KIáº¾N TRÃšC TÃ“M Táº®T:

### **Components:**

```
1. INPUT
   â†“
2. ViSoBERT ENCODER (shared)
   [batch, 768]
   â†“
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â†“                     â†“                     â†“
3A. CLASSIFICATION     3B. PROJECTION
    Dense(512)             Projection(256)
    Dropout(0.3)           L2 Normalize
    Output(11Ã—3)
    â†“                     â†“
4A. LOGITS             4B. EMBEDDINGS
    [batch,11,3]          [batch,256]
    â†“                     â†“
5A. FOCAL LOSS         5B. CONTRASTIVE LOSS
    (classification)       (representation)
    â†“                     â†“
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
6. COMBINED LOSS: 0.8*Focal + 0.2*Contrastive
                    â†“
7. BACKPROPAGATION
   Updates: Encoder + Both heads
```

---

## â±ï¸ TIMING (1 iteration):

```
Action              Time    Type
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€
Load batch          0ms     
Forward: Encoder    5-10ms  Sequential
Forward: 2 heads    5ms     PARALLEL âœ…
Calculate losses    10ms    PARALLEL âœ…
Combine             1ms     
Backward            30ms    
Optimizer step      10ms    
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€
TOTAL               ~70ms   
```

**Náº¿u cháº¡y tuáº§n tá»± (sai):** ~160ms (cháº­m hÆ¡n 2x)

---

## ğŸ’¡ KEY INSIGHTS:

### **1. Single Forward Pass**
```python
# NOT this:
logits = model(x)
focal_loss = focal_fn(logits)
logits.backward()

embeddings = model(x)  # â† Forward láº§n 2 (WRONG!)
contr_loss = contr_fn(embeddings)
contr_loss.backward()

# BUT this:
logits, embeddings = model(x, return_embeddings=True)  # â† 1 forward
focal_loss = focal_fn(logits)
contr_loss = contr_fn(embeddings)
total_loss = 0.8*focal + 0.2*contr
total_loss.backward()  # â† 1 backward
```

### **2. Parallel Branches**
```
Encoder output [batch, 768]
    â†“
    â”œâ†’ Classification head (logits)   } Cháº¡y CÃ™NG LÃšC
    â””â†’ Projection head (embeddings)   }
```

### **3. Complementary Losses**
```
Focal Loss:
  - Focus: Hard examples
  - Goal: Better classification
  - Input: Logits

Contrastive Loss:
  - Focus: Sample relationships
  - Goal: Better representation
  - Input: Embeddings

Combined:
  â†’ Best of both! âœ…
```

### **4. Single Backprop**
```
Combined Loss
    â†“
Gradient flows to:
  - Encoder (learns for BOTH tasks)
  - Classification head (from focal)
  - Projection head (from contrastive)
    
All updated TOGETHER
```

---

## ğŸ¯ GIAI ÄOáº N THAM GIA:

| Giai Ä‘oáº¡n | Focal Loss | Contrastive Loss |
|-----------|-----------|------------------|
| **Input** | - | - |
| **Encoder** | - | - |
| **Branches** | Classification head | Projection head |
| **Outputs** | Logits [b,11,3] | Embeddings [b,256] |
| **Loss Calc** | âœ… TÃ­nh tá»« logits | âœ… TÃ­nh tá»« embeddings |
| **Combine** | âœ… 80% weight | âœ… 20% weight |
| **Backprop** | âœ… Update class head | âœ… Update proj head |

**Cáº£ 2 cÃ¹ng tham gia tá»« sau Encoder Ä‘áº¿n háº¿t Backprop!**

---

## ğŸ“Š SO SÃNH:

### **Focal Loss Only:**
```
Model: ViSoBERT + Classification head
Loss: Focal only
F1: ~95.0%

Pros: Good classification
Cons: Representation khÃ´ng tá»‘t
```

### **Contrastive Loss Only:**
```
Model: ViSoBERT + Classification + Projection
Loss: Contrastive only
F1: ~95.4%

Pros: Good representation
Cons: Classification khÃ´ng optimal
```

### **Focal + Contrastive (Our Approach):**
```
Model: ViSoBERT + Both heads
Loss: 0.8*Focal + 0.2*Contrastive
F1: ~96.0% âœ…

Pros: 
  - Excellent classification (focal)
  - Excellent representation (contrastive)
  - Best of both worlds!
  
Cons: 
  - Slightly more complex
  - (but not slower!)
```

---

## ğŸ” CODE WALKTHROUGH:

### **Model Definition:**
```python
class MultiLabelViSoBERTFocalContrastive(nn.Module):
    def __init__(self):
        # Encoder (shared)
        self.bert = AutoModel.from_pretrained("visobert")
        
        # Classification head (for focal)
        self.dense = nn.Linear(768, 512)
        self.dropout = nn.Dropout(0.3)
        self.out = nn.Linear(512, 11*3)
        
        # Projection head (for contrastive)
        self.projection = nn.Linear(768, 256)
    
    def forward(self, input_ids, attention_mask, return_embeddings=False):
        # 1. Encoder (shared)
        outputs = self.bert(input_ids, attention_mask)
        pooled = outputs.pooler_output  # [batch, 768]
        
        # 2. Classification branch
        x = F.relu(self.dense(pooled))
        x = self.dropout(x)
        logits = self.out(x).view(-1, 11, 3)
        
        if return_embeddings:
            # 3. Projection branch
            embeddings = self.projection(pooled)
            embeddings = F.normalize(embeddings, p=2, dim=1)
            return logits, embeddings  # â† BOTH outputs
        
        return logits
```

### **Training Step:**
```python
for batch in dataloader:
    input_ids, labels = batch
    
    # 1. Forward (BOTH outputs)
    logits, embeddings = model(
        input_ids, 
        attention_mask, 
        return_embeddings=True  # â† Get both!
    )
    
    # 2. Calculate losses (SIMULTANEOUSLY)
    focal_loss = focal_fn(logits, labels)
    contr_loss = contr_fn(embeddings, labels)
    
    # 3. Combine
    total_loss = 0.8 * focal_loss + 0.2 * contr_loss
    
    # 4. Backprop (SINGLE)
    optimizer.zero_grad()
    total_loss.backward()
    optimizer.step()
```

---

## âœ… SUMMARY:

### **CÃ¢u há»i â†’ Tráº£ lá»i:**

| CÃ¢u há»i | Tráº£ lá»i |
|---------|---------|
| Cháº¡y cÃ¹ng lÃºc hay riÃªng láº»? | **CÃ™NG LÃšC** âœ… |
| Focal trÆ°á»›c hay Contrastive? | **KHÃ”NG cÃ³ - PARALLEL** âœ… |
| Máº¥y forward pass? | **1** âœ… |
| Máº¥y backprop? | **1** âœ… |
| CÃ³ cháº­m khÃ´ng? | **KHÃ”NG** âœ… |
| Tham gia giai Ä‘oáº¡n nÃ o? | **Sau Encoder, trong Training** âœ… |

### **Key Concept:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PARALLEL MULTI-TASK LEARNING       â”‚
â”‚                                     â”‚
â”‚  Single model, two objectives:      â”‚
â”‚    1. Classification (Focal)        â”‚
â”‚    2. Representation (Contrastive)  â”‚
â”‚                                     â”‚
â”‚  Learned SIMULTANEOUSLY in one pass â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“š FILES REFERENCE:

### **Visualizations:**
- `model_architecture.png` - Complete architecture
- `forward_pass_timeline.png` - Step-by-step timeline
- `sequential_vs_parallel.png` - Comparison

### **Code:**
- `visualize_model_architecture.py` - Generate visuals
- `multi_label/model_multilabel_focal_contrastive.py` - Model class
- `multi_label/train_multilabel_focal_contrastive.py` - Training loop

### **Docs:**
- `MODEL_ARCHITECTURE_EXPLAINED.md` - Detailed explanation
- `ARCHITECTURE_VISUALIZATION_COMPLETE.md` - This file

---

## ğŸ‰ DONE!

**ÄÃ£ visual Ä‘áº§y Ä‘á»§:**
- âœ… 3 PNG visualizations
- âœ… Detailed explanation document
- âœ… Code walkthrough
- âœ… Timing analysis
- âœ… Q&A comprehensive

**Xem ngay:**
```bash
start model_architecture.png
```

**Äá»c thÃªm:**
```
MODEL_ARCHITECTURE_EXPLAINED.md
```
