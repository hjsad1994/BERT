"""
Script Test Sentiment SMART vá»›i Aspect Relevance Detection
==========================================================
Chá»‰ hiá»ƒn thá»‹ cÃ¡c aspect THá»°C Sá»° Ä‘Æ°á»£c Ä‘á» cáº­p trong cÃ¢u
Sá»­ dá»¥ng keyword matching + confidence filtering

Usage:
    python test_sentiment_smart.py
    python test_sentiment_smart.py --sentence "pin tá»‡ quÃ¡"
    python test_sentiment_smart.py --sentence "pin tá»‡ quÃ¡" --show-ignored
    python test_sentiment_smart.py --batch test_examples.txt
"""

import sys
import io
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

import os
import argparse
import torch
import numpy as np
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import re
from colorama import init, Fore, Style

init(autoreset=True)

# Configuration
MODEL_PATH = "finetuned_visobert_absa_model"
MAX_LENGTH = 256

# Aspect keywords (tá»« khÃ³a tiáº¿ng Viá»‡t cho má»—i aspect)
ASPECT_KEYWORDS = {
    'Battery': [
        'pin', 'sáº¡c', 'xáº¡c', 'dung lÆ°á»£ng pin', 'mah', 'battery', 'trÃ¢u pin',
        'háº¿t pin', 'tá»¥t pin', 'chai pin', 'phÃ¬nh pin', 'tá»‘n pin', 'ngá»‘n pin'
    ],
    'Camera': [
        'camera', 'cam', 'chá»¥p', 'quay', 'áº£nh', 'hÃ¬nh', 'selfie', 'tele',
        'zoom', 'gÃ³c rá»™ng', 'chÃ¢n dung', 'macro', 'á»‘ng kÃ­nh', 'megapixel', 'mp'
    ],
    'Performance': [
        'hiá»‡u nÄƒng', 'mÆ°á»£t', 'lag', 'giáº­t', 'Ä‘Æ¡', 'nhanh', 'cháº­m', 'máº¡nh',
        'yáº¿u', 'chip', 'cpu', 'gpu', 'ram', 'snapdragon', 'mediatek', 'dimensity',
        'xá»­ lÃ½', 'Ä‘a nhiá»‡m', 'gaming', 'game', 'fps'
    ],
    'Display': [
        'mÃ n hÃ¬nh', 'mÃ n', 'screen', 'display', 'hiá»ƒn thá»‹', 'Ä‘á»™ phÃ¢n giáº£i',
        'amoled', 'lcd', 'oled', 'ips', 'táº¥m ná»n', 'hz', 'refresh rate',
        'sÃ¡ng', 'tá»‘i', 'náº¯ng', 'xem phim', 'sáº¯c nÃ©t', 'má»', 'tráº§y mÃ n'
    ],
    'Design': [
        'thiáº¿t káº¿', 'Ä‘áº¹p', 'xáº¥u', 'sang', 'bÃ³ng', 'nhÃ¡m', 'vuÃ´ng', 'trÃ²n',
        'kim loáº¡i', 'nhá»±a', 'kÃ­nh', 'vá»', 'khung', 'cáº§m', 'náº¯m', 'ergonomic',
        'mÃ u', 'color', 'style', 'kiá»ƒu dÃ¡ng', 'ngoáº¡i hÃ¬nh', 'bá» ngoÃ i'
    ],
    'Software': [
        'pháº§n má»m', 'software', 'há»‡ Ä‘iá»u hÃ nh', 'os', 'android', 'ios',
        'miui', 'one ui', 'coloros', 'funtouch', 'realme ui', 'oxygen',
        'update', 'cáº­p nháº­t', 'app', 'á»©ng dá»¥ng', 'bloatware', 'quáº£ng cÃ¡o'
    ],
    'Packaging': [
        'Ä‘Ã³ng gÃ³i', 'há»™p', 'box', 'bao bÃ¬', 'packaging', 'gÃ³i', 'niÃªm phong',
        'seal', 'tem', 'fullbox', 'nguyÃªn seal'
    ],
    'Price': [
        'giÃ¡', 'price', 'tiá»n', 'ráº»', 'Ä‘áº¯t', 'máº¯c', 'pháº£i chÄƒng', 'há»£p lÃ½',
        'cost', 'budget', 'tÃºi tiá»n', 'khoáº£n', 'vnÄ‘', 'triá»‡u', 'nghÃ¬n',
        'giÃ¡ trá»‹', 'value', 'Ä‘Ã¡ng giÃ¡'
    ],
    'Audio': [
        'Ã¢m thanh', 'audio', 'loa', 'speaker', 'tiáº¿ng', 'nghe', 'nghe nháº¡c',
        'Ã¢m', 'bass', 'treble', 'stereo', 'mono', 'volume', 'Ã¢m lÆ°á»£ng',
        'to', 'nhá»', 'rÃ¨', 'rÃ­t', 'dolby', 'hifi', 'cháº¥t lÆ°á»£ng Ã¢m thanh'
    ],
    'Warranty': [
        'báº£o hÃ nh', 'warranty', 'bh', 'Ä‘á»•i tráº£', 'guarantee', 'há»— trá»£',
        'claim', 'sá»­a chá»¯a', 'service center', 'trung tÃ¢m báº£o hÃ nh'
    ],
    'Shop_Service': [
        'shop', 'cá»­a hÃ ng', 'store', 'seller', 'ngÆ°á»i bÃ¡n', 'chá»§ shop',
        'tÆ° váº¥n', 'há»— trá»£', 'nhiá»‡t tÃ¬nh', 'thÃ¡i Ä‘á»™', 'phá»¥c vá»¥', 'service',
        'chÄƒm sÃ³c', 'tráº£ lá»i', 'chat'
    ],
    'Shipping': [
        'giao hÃ ng', 'ship', 'váº­n chuyá»ƒn', 'delivery', 'shipper', 'giao',
        'nháº­n hÃ ng', 'ship nhanh', 'ship cháº­m', 'giao nhanh', 'giao cháº­m',
        'shipper', 'Ä‘Ã³ng gÃ³i giao hÃ ng'
    ],
    'General': [
        'mÃ¡y', 'Ä‘iá»‡n thoáº¡i', 'phone', 'smartphone', 'device', 'sáº£n pháº©m',
        'product', 'hÃ ng', 'overall', 'tá»•ng thá»ƒ', 'chung', 'nÃ³i chung',
        'tá»‘t', 'xáº¥u', 'ok', 'oke', 'á»•n', 'Ä‘Æ°á»£c'
    ],
    'Others': [
        'khÃ¡c', 'other', 'phá»¥ kiá»‡n', 'accessory', 'tai nghe', 'sáº¡c dá»± phÃ²ng'
    ]
}

ID2LABEL = {0: 'positive', 1: 'negative', 2: 'neutral'}
LABEL2ID = {'positive': 0, 'negative': 1, 'neutral': 2}


def check_aspect_relevance(sentence, aspect):
    """
    Kiá»ƒm tra xem aspect cÃ³ Ä‘Æ°á»£c Ä‘á» cáº­p trong cÃ¢u khÃ´ng
    
    Returns:
        float: relevance score (0.0 - 1.0)
    """
    sentence_lower = sentence.lower()
    keywords = ASPECT_KEYWORDS.get(aspect, [])
    
    if not keywords:
        return 0.0
    
    # Äáº¿m sá»‘ keywords xuáº¥t hiá»‡n
    matches = 0
    for keyword in keywords:
        if keyword.lower() in sentence_lower:
            matches += 1
    
    # Relevance score = sá»‘ keywords match / tá»•ng sá»‘ keywords
    # Bonus náº¿u cÃ³ Ã­t nháº¥t 1 match
    if matches > 0:
        base_score = matches / len(keywords)
        # Boost score náº¿u cÃ³ match (Ã­t nháº¥t 0.3)
        relevance_score = max(0.3, min(1.0, base_score * 5))
        return relevance_score
    
    return 0.0


class SmartSentimentPredictor:
    """Predictor thÃ´ng minh vá»›i aspect relevance detection"""
    
    def __init__(self, model_path=MODEL_PATH):
        """Khá»Ÿi táº¡o predictor"""
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"ğŸ”§ Äang load mÃ´ hÃ¬nh tá»«: {model_path}")
        print(f"ğŸ”§ Device: {self.device}")
        
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(model_path)
            self.model = AutoModelForSequenceClassification.from_pretrained(model_path)
            self.model.to(self.device)
            self.model.eval()
            print(f"âœ“ Load mÃ´ hÃ¬nh thÃ nh cÃ´ng!\n")
        except Exception as e:
            print(f"âŒ Lá»—i khi load mÃ´ hÃ¬nh: {str(e)}")
            sys.exit(1)
    
    def predict_single(self, sentence, aspect):
        """Dá»± Ä‘oÃ¡n sentiment cho má»™t aspect"""
        # Xá»­ lÃ½ VNCoreNLP segmentation náº¿u cÃ³
        sentence = sentence.replace('_', ' ')
        
        inputs = self.tokenizer(
            sentence, aspect,
            return_tensors='pt',
            max_length=MAX_LENGTH,
            truncation=True,
            padding=True
        )
        
        inputs = {k: v.to(self.device) for k, v in inputs.items()}
        
        with torch.no_grad():
            outputs = self.model(**inputs)
            logits = outputs.logits
            probs = torch.softmax(logits, dim=-1).cpu().numpy()[0]
        
        predicted_idx = np.argmax(probs)
        predicted_sentiment = ID2LABEL[predicted_idx]
        confidence = probs[predicted_idx]
        
        probabilities = {
            ID2LABEL[i]: float(probs[i]) for i in range(len(probs))
        }
        
        return {
            'aspect': aspect,
            'sentiment': predicted_sentiment,
            'confidence': float(confidence),
            'probabilities': probabilities
        }
    
    def predict_smart(self, sentence, confidence_threshold=0.7, relevance_threshold=0.3):
        """
        Dá»± Ä‘oÃ¡n THÃ”NG MINH - chá»‰ aspects Ä‘Æ°á»£c Ä‘á» cáº­p
        
        Args:
            sentence: CÃ¢u cáº§n phÃ¢n tÃ­ch
            confidence_threshold: NgÆ°á»¡ng confidence tá»‘i thiá»ƒu
            relevance_threshold: NgÆ°á»¡ng relevance tá»‘i thiá»ƒu (aspect Ä‘Æ°á»£c Ä‘á» cáº­p)
            
        Returns:
            dict: {
                'relevant_aspects': list (aspects Ä‘Æ°á»£c Ä‘á» cáº­p vá»›i sentiment),
                'all_results': list (táº¥t cáº£ aspects),
                'ignored_aspects': list (aspects bá»‹ ignore vÃ¬ khÃ´ng relevance)
            }
        """
        all_results = []
        relevant_aspects = []
        ignored_aspects = []
        
        print(f"\n{Fore.CYAN}ğŸ” Äang phÃ¢n tÃ­ch aspect relevance...{Style.RESET_ALL}")
        
        for aspect in ASPECT_KEYWORDS.keys():
            # Check relevance
            relevance_score = check_aspect_relevance(sentence, aspect)
            
            # Predict sentiment
            result = self.predict_single(sentence, aspect)
            result['relevance_score'] = relevance_score
            
            all_results.append(result)
            
            # Chá»‰ thÃªm vÃ o relevant náº¿u:
            # 1. CÃ³ relevance score > threshold
            # 2. Confidence > threshold
            # 3. KhÃ´ng pháº£i neutral (hoáº·c neutral vá»›i confidence tháº¥p)
            if relevance_score >= relevance_threshold:
                if result['confidence'] >= confidence_threshold:
                    relevant_aspects.append(result)
                elif result['sentiment'] != 'neutral':
                    # Aspect Ä‘Æ°á»£c Ä‘á» cáº­p nhÆ°ng confidence tháº¥p - váº«n thÃªm vÃ o
                    relevant_aspects.append(result)
            else:
                ignored_aspects.append({
                    'aspect': aspect,
                    'reason': f'Not mentioned (relevance: {relevance_score:.2f})'
                })
        
        # Sort by relevance score
        relevant_aspects = sorted(relevant_aspects, 
                                 key=lambda x: (x['relevance_score'], x['confidence']), 
                                 reverse=True)
        
        return {
            'relevant_aspects': relevant_aspects,
            'all_results': all_results,
            'ignored_aspects': ignored_aspects
        }


def format_sentiment_emoji(sentiment):
    """Emoji cho sentiment"""
    return {'positive': 'ğŸ˜Š', 'negative': 'ğŸ˜', 'neutral': 'ğŸ˜'}.get(sentiment, '')


def format_confidence_bar(confidence, width=20):
    """Progress bar"""
    filled = int(confidence * width)
    return 'â–ˆ' * filled + 'â–‘' * (width - filled)


def print_smart_results(sentence, results, show_ignored=False):
    """In káº¿t quáº£ thÃ´ng minh"""
    print(f"\n{'='*80}")
    print(f"ğŸ“ CÃ¢u phÃ¢n tÃ­ch: {Fore.CYAN}{sentence}{Style.RESET_ALL}")
    print(f"{'='*80}\n")
    
    relevant = results['relevant_aspects']
    ignored = results['ignored_aspects']
    
    if relevant:
        print(f"{Fore.GREEN}ğŸ¯ CÃC ASPECT ÄÆ¯á»¢C Äá»€ Cáº¬P:{Style.RESET_ALL}\n")
        
        for idx, result in enumerate(relevant, 1):
            aspect = result['aspect']
            sentiment = result['sentiment']
            confidence = result['confidence']
            relevance = result['relevance_score']
            emoji = format_sentiment_emoji(sentiment)
            
            # MÃ u theo sentiment
            color = {
                'positive': Fore.GREEN,
                'negative': Fore.RED,
                'neutral': Fore.YELLOW
            }.get(sentiment, '')
            
            print(f"{idx}. {Fore.CYAN}{aspect:<15}{Style.RESET_ALL} â†’ "
                  f"{emoji} {color}{sentiment.upper():<10}{Style.RESET_ALL}")
            print(f"   Confidence: {confidence:.1%} | Relevance: {relevance:.1%}")
            
            # Progress bars
            conf_bar = format_confidence_bar(confidence)
            rel_bar = format_confidence_bar(relevance)
            print(f"   Conf: {conf_bar} {confidence:.2%}")
            print(f"   Relv: {rel_bar} {relevance:.2%}\n")
    else:
        print(f"{Fore.YELLOW}âš ï¸  KhÃ´ng phÃ¡t hiá»‡n aspect cá»¥ thá»ƒ nÃ o Ä‘Æ°á»£c Ä‘á» cáº­p{Style.RESET_ALL}\n")
    
    # Hiá»ƒn thá»‹ aspects bá»‹ ignore
    if show_ignored and ignored:
        print(f"\n{Fore.BLUE}ğŸš« ASPECTS Bá»Š Bá» QUA (khÃ´ng Ä‘Æ°á»£c Ä‘á» cáº­p):{Style.RESET_ALL}")
        for item in ignored[:5]:  # Chá»‰ hiá»ƒn thá»‹ 5 cÃ¡i Ä‘áº§u
            print(f"   â€¢ {item['aspect']}: {item['reason']}")
        if len(ignored) > 5:
            print(f"   ... vÃ  {len(ignored) - 5} aspects khÃ¡c")


def print_compact_results(sentence, results):
    """In káº¿t quáº£ dáº¡ng compact cho batch mode"""
    relevant = results['relevant_aspects']
    
    print(f"\nğŸ“ \"{sentence}\"")
    
    if relevant:
        print(f"â†’ PhÃ¡t hiá»‡n {len(relevant)} aspect(s) Ä‘Æ°á»£c Ä‘á» cáº­p:")
        for r in relevant:
            emoji = format_sentiment_emoji(r['sentiment'])
            print(f"   â€¢ {r['aspect']}: {emoji} {r['sentiment']} "
                  f"(conf: {r['confidence']:.1%}, rel: {r['relevance_score']:.1%})")
    else:
        print(f"â†’ KhÃ´ng phÃ¡t hiá»‡n aspect cá»¥ thá»ƒ nÃ o")
    print()


def batch_mode(predictor, sentences):
    """Cháº¿ Ä‘á»™ batch - test nhiá»u cÃ¢u tá»« file"""
    print(f"\n{'='*80}")
    print(f"{Fore.GREEN}ğŸ“¦ CHáº¾ Äá»˜ BATCH - Test {len(sentences)} cÃ¢u{Style.RESET_ALL}")
    print(f"{'='*80}\n")
    
    for idx, sentence in enumerate(sentences, 1):
        print(f"{Fore.BLUE}[{idx}/{len(sentences)}]{Style.RESET_ALL}", end=" ")
        
        # Predict
        results = predictor.predict_smart(sentence)
        
        # Print compact
        print_compact_results(sentence, results)


def interactive_mode(predictor):
    """Cháº¿ Ä‘á»™ tÆ°Æ¡ng tÃ¡c"""
    print(f"\n{'='*80}")
    print(f"{Fore.GREEN}ğŸ”® CHáº¾ Äá»˜ TÆ¯Æ NG TÃC THÃ”NG MINH - SMART ABSA{Style.RESET_ALL}")
    print(f"{'='*80}")
    print(f"\nTÃ­nh nÄƒng:")
    print(f"  â€¢ Tá»± Ä‘á»™ng phÃ¡t hiá»‡n aspects Ä‘Æ°á»£c Ä‘á» cáº­p trong cÃ¢u")
    print(f"  â€¢ Lá»c bá» aspects khÃ´ng liÃªn quan")
    print(f"  â€¢ Hiá»ƒn thá»‹ relevance score cho má»—i aspect")
    print(f"\nHÆ°á»›ng dáº«n:")
    print(f"  â€¢ Nháº­p cÃ¢u Ä‘á»ƒ phÃ¢n tÃ­ch")
    print(f"  â€¢ GÃµ 'ignored' sau cÃ¢u Ä‘á»ƒ xem aspects bá»‹ bá» qua")
    print(f"  â€¢ GÃµ 'quit' Ä‘á»ƒ thoÃ¡t")
    print(f"\n{'-'*80}\n")
    
    while True:
        try:
            user_input = input(f"{Fore.YELLOW}Nháº­p cÃ¢u:{Style.RESET_ALL} ").strip()
            
            if not user_input:
                continue
            
            if user_input.lower() in ['quit', 'exit', 'q']:
                print(f"\n{Fore.CYAN}ğŸ‘‹ Táº¡m biá»‡t!{Style.RESET_ALL}\n")
                break
            
            # Check show ignored
            show_ignored = False
            if user_input.lower().endswith(' ignored'):
                show_ignored = True
                user_input = user_input[:-8].strip()
            
            # Predict
            print(f"\n{Fore.CYAN}â³ Äang phÃ¢n tÃ­ch...{Style.RESET_ALL}")
            results = predictor.predict_smart(user_input)
            
            # Print results
            print_smart_results(user_input, results, show_ignored=show_ignored)
            
            print(f"\n{'-'*80}\n")
            
        except KeyboardInterrupt:
            print(f"\n\n{Fore.CYAN}ğŸ‘‹ Táº¡m biá»‡t!{Style.RESET_ALL}\n")
            break
        except Exception as e:
            print(f"\n{Fore.RED}âŒ Lá»—i: {str(e)}{Style.RESET_ALL}\n")


def main():
    """Main function"""
    parser = argparse.ArgumentParser(
        description='Test sentiment THÃ”NG MINH vá»›i aspect relevance detection'
    )
    parser.add_argument('--sentence', '-s', type=str, help='CÃ¢u cáº§n test')
    parser.add_argument('--batch', '-b', type=str, 
                       help='File chá»©a danh sÃ¡ch cÃ¢u (má»—i dÃ²ng má»™t cÃ¢u)')
    parser.add_argument('--show-ignored', action='store_true', 
                       help='Hiá»ƒn thá»‹ aspects bá»‹ ignore')
    
    args = parser.parse_args()
    
    if not os.path.exists(MODEL_PATH):
        print(f"\n{Fore.RED}âŒ KhÃ´ng tÃ¬m tháº¥y mÃ´ hÃ¬nh táº¡i: {MODEL_PATH}{Style.RESET_ALL}\n")
        return
    
    # Initialize predictor
    predictor = SmartSentimentPredictor(MODEL_PATH)
    
    # Batch mode
    if args.batch:
        if not os.path.exists(args.batch):
            print(f"\n{Fore.RED}âŒ KhÃ´ng tÃ¬m tháº¥y file: {args.batch}{Style.RESET_ALL}\n")
            return
        
        with open(args.batch, 'r', encoding='utf-8') as f:
            sentences = [line.strip() for line in f if line.strip()]
        
        batch_mode(predictor, sentences)
        return
    
    # Test sentence
    if args.sentence:
        results = predictor.predict_smart(args.sentence)
        print_smart_results(args.sentence, results, show_ignored=args.show_ignored)
        return
    
    # Interactive mode
    interactive_mode(predictor)


if __name__ == '__main__':
    main()
