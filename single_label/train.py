"""
Script Hu·∫•n Luy·ªán M√¥ H√¨nh ABSA
==============================
Script ch√≠nh ƒë·ªÉ fine-tune m√¥ h√¨nh Vietnamese-Sentiment-visobert 
cho nhi·ªám v·ª• Aspect-Based Sentiment Analysis (ABSA)

Usage:
    python train.py --config config.yaml
"""

import os
import sys
import argparse
import torch
import logging
from datetime import datetime
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
    set_seed as hf_set_seed,
    EarlyStoppingCallback
)

# Import c√°c h√†m ti·ªán √≠ch
from utils import (
    load_config,
    set_seed,
    load_and_preprocess_data,
    ABSADataset,
    compute_metrics,
    save_predictions,
    save_predictions_from_output,
    get_detailed_metrics,
    print_system_info
)


class TeeLogger:
    """Logger ghi ƒë·ªìng th·ªùi ra console v√† file"""
    def __init__(self, log_file):
        self.terminal = sys.stdout
        self.log = open(log_file, 'w', encoding='utf-8')
    
    def write(self, message):
        # Handle console encoding errors (replace problematic chars)
        try:
            self.terminal.write(message)
        except UnicodeEncodeError:
            # Fallback: replace emoji/special chars with ASCII
            safe_message = message.encode('ascii', errors='replace').decode('ascii')
            self.terminal.write(safe_message)
        
        # Always write full UTF-8 to file
        self.log.write(message)
        self.log.flush()
    
    def flush(self):
        self.terminal.flush()
        self.log.flush()
    
    def close(self):
        self.log.close()


def setup_logging():
    """Thi·∫øt l·∫≠p logging ra file v·ªõi timestamp"""
    # T·∫°o t√™n file log v·ªõi timestamp
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_dir = "single_label/training_logs"
    os.makedirs(log_dir, exist_ok=True)
    log_file = os.path.join(log_dir, f"training_log_{timestamp}.txt")
    
    # T·∫°o TeeLogger ƒë·ªÉ ghi c·∫£ console v√† file
    tee = TeeLogger(log_file)
    sys.stdout = tee
    sys.stderr = tee
    
    print(f"üìù Training log s·∫Ω ƒë∆∞·ª£c l∆∞u t·∫°i: {log_file}\n")
    
    return tee, log_file


def parse_arguments():
    """Parse command line arguments"""
    parser = argparse.ArgumentParser(
        description='Fine-tune ViSoBERT cho ABSA tr√™n d·ªØ li·ªáu ti·∫øng Vi·ªát'
    )
    parser.add_argument(
        '--config',
        type=str,
        default='config.yaml',
        help='ƒê∆∞·ªùng d·∫´n ƒë·∫øn file c·∫•u h√¨nh YAML (default: config.yaml)'
    )
    return parser.parse_args()


def main():
    """H√†m main ƒëi·ªÅu ph·ªëi to√†n b·ªô workflow"""
    
    # =====================================================================
    # 0. SETUP LOGGING TO FILE
    # =====================================================================
    tee_logger, log_file_path = setup_logging()
    
    # =====================================================================
    # 1. PARSE ARGUMENTS V√Ä LOAD CONFIG
    # =====================================================================
    print("\n" + "="*70)
    print("üöÄ FINE-TUNING VISOBERT CHO ABSA")
    print("="*70)
    
    args = parse_arguments()
    
    # Load c·∫•u h√¨nh
    try:
        config = load_config(args.config)
    except Exception as e:
        print(f"\n‚ùå L·ªói khi load config: {str(e)}")
        return
    
    # =====================================================================
    # 2. THI·∫æT L·∫¨P SEED V√Ä IN TH√îNG TIN H·ªÜ TH·ªêNG
    # =====================================================================
    # Get training seed from reproducibility config
    seed = config['reproducibility']['training_seed']
    set_seed(seed)
    hf_set_seed(seed)  # Set seed cho transformers
    
    print_system_info()
    
    # =====================================================================
    # 3. PH√ÅT HI·ªÜN V√Ä THI·∫æT L·∫¨P DEVICE (GPU/CPU)
    # =====================================================================
    if torch.cuda.is_available():
        device = torch.device('cuda')
        print(f"‚úì S·ª≠ d·ª•ng GPU: {torch.cuda.get_device_name(0)}")
    else:
        device = torch.device('cpu')
        print(f"‚úì S·ª≠ d·ª•ng CPU")
    
    print(f"‚úì Device: {device}")
    
    # =====================================================================
    # 4. T·∫¢I TOKENIZER V√Ä M√î H√åNH
    # =====================================================================
    print(f"\n{'='*70}")
    print("ü§ñ ƒêang t·∫£i tokenizer v√† m√¥ h√¨nh...")
    print(f"{'='*70}")
    
    model_name = config['model']['name']
    num_labels = config['model']['num_labels']
    
    try:
        print(f"\n‚úì ƒêang t·∫£i tokenizer t·ª´: {model_name}")
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        
        print(f"‚úì ƒêang t·∫£i m√¥ h√¨nh t·ª´: {model_name}")
        model = AutoModelForSequenceClassification.from_pretrained(
            model_name,
            num_labels=num_labels
        )
        
        print(f"‚úì Tokenizer vocab size: {tokenizer.vocab_size}")
        print(f"‚úì Model parameters: {model.num_parameters():,}")
        print(f"‚úì S·ªë l∆∞·ª£ng labels: {num_labels}")
        
    except Exception as e:
        print(f"\n‚ùå L·ªói khi t·∫£i m√¥ h√¨nh: {str(e)}")
        print(f"\nG·ª£i √Ω: Ki·ªÉm tra k·∫øt n·ªëi internet ho·∫∑c t√™n m√¥ h√¨nh trong config.yaml")
        return
    
    # =====================================================================
    # 5. T·∫¢I V√Ä X·ª¨ L√ù D·ªÆ LI·ªÜU
    # =====================================================================
    try:
        train_df, val_df, test_df, label_map, id2label = load_and_preprocess_data(config)
    except Exception as e:
        print(f"\n‚ùå L·ªói khi load d·ªØ li·ªáu: {str(e)}")
        print(f"\nG·ª£i √Ω: Ch·∫°y 'python prepare_data.py' ƒë·ªÉ t·∫°o d·ªØ li·ªáu tr∆∞·ªõc")
        return
    
    # =====================================================================
    # 6. T·∫†O DATASETS
    # =====================================================================
    print(f"\n{'='*70}")
    print("üì¶ ƒêang t·∫°o PyTorch Datasets...")
    print(f"{'='*70}")
    
    max_length = config['model']['max_length']
    
    try:
        train_dataset = ABSADataset(train_df, tokenizer, max_length)
        val_dataset = ABSADataset(val_df, tokenizer, max_length)
        test_dataset = ABSADataset(test_df, tokenizer, max_length)
        
        print(f"\n‚úì Train dataset: {len(train_dataset)} m·∫´u")
        print(f"‚úì Val dataset:   {len(val_dataset)} m·∫´u")
        print(f"‚úì Test dataset:  {len(test_dataset)} m·∫´u")
        
        # In m·ªôt m·∫´u ƒë·ªÉ ki·ªÉm tra
        print(f"\n‚úì V√≠ d·ª• m·ªôt m·∫´u ƒë√£ tokenize:")
        sample = train_dataset[0]
        print(f"   Input IDs shape:      {sample['input_ids'].shape}")
        print(f"   Attention mask shape: {sample['attention_mask'].shape}")
        print(f"   Token type IDs shape: {sample['token_type_ids'].shape}")
        print(f"   Label:                {sample['labels'].item()} ({id2label[sample['labels'].item()]})")
        
    except Exception as e:
        print(f"\n‚ùå L·ªói khi t·∫°o datasets: {str(e)}")
        return
    
    # =====================================================================
    # 7. THI·∫æT L·∫¨P TRAINING ARGUMENTS
    # =====================================================================
    print(f"\n{'='*70}")
    print("‚öôÔ∏è  ƒêang thi·∫øt l·∫≠p Training Arguments...")
    print(f"{'='*70}")
    
    training_config = config['training']
    output_dir = config['paths']['output_dir']
    
    training_args = TrainingArguments(
        # Output directory
        output_dir=output_dir,
        
        # Training parameters
        num_train_epochs=training_config['num_train_epochs'],
        per_device_train_batch_size=training_config['per_device_train_batch_size'],
        per_device_eval_batch_size=training_config['per_device_eval_batch_size'],
        gradient_accumulation_steps=training_config['gradient_accumulation_steps'],
        
        # Optimizer
        learning_rate=training_config['learning_rate'],
        weight_decay=training_config['weight_decay'],
        adam_beta1=training_config['adam_beta1'],
        adam_beta2=training_config['adam_beta2'],
        adam_epsilon=training_config['adam_epsilon'],
        max_grad_norm=training_config['max_grad_norm'],
        
        # Scheduler
        warmup_ratio=training_config['warmup_ratio'],
        lr_scheduler_type=training_config['lr_scheduler_type'],
        
        # Evaluation
        eval_strategy=training_config['evaluation_strategy'],
        save_strategy=training_config['save_strategy'],
        save_total_limit=training_config['save_total_limit'],
        load_best_model_at_end=training_config['load_best_model_at_end'],
        metric_for_best_model=training_config['metric_for_best_model'],
        greater_is_better=training_config['greater_is_better'],
        
        # Logging
        logging_steps=training_config['logging_steps'],
        logging_first_step=training_config['logging_first_step'],
        
        # Performance
        fp16=training_config['fp16'],
        fp16_full_eval=training_config.get('fp16_full_eval', False),
        optim=training_config.get('optim', 'adamw_torch'),
        dataloader_num_workers=training_config['dataloader_num_workers'],
        dataloader_pin_memory=training_config['dataloader_pin_memory'],
        dataloader_prefetch_factor=training_config.get('dataloader_prefetch_factor', 2),
        dataloader_persistent_workers=training_config.get('dataloader_persistent_workers', False),
        
        # Other
        seed=config['reproducibility']['training_seed'],
        data_seed=config['reproducibility']['dataloader_seed'],
        disable_tqdm=training_config['disable_tqdm'],
        remove_unused_columns=training_config['remove_unused_columns'],
    )
    
    print(f"\n‚úì C√°c tham s·ªë hu·∫•n luy·ªán ch√≠nh:")
    print(f"   Learning rate:        {training_config['learning_rate']}")
    print(f"   LR Scheduler:         {training_config['lr_scheduler_type']}")
    print(f"   Optimizer:            {training_config.get('optim', 'adamw_torch')}")
    print(f"   Epochs:               {training_config['num_train_epochs']}")
    print(f"   Train batch size:     {training_config['per_device_train_batch_size']}")
    print(f"   Eval batch size:      {training_config['per_device_eval_batch_size']}")
    print(f"   Gradient accum:       {training_config['gradient_accumulation_steps']}")
    print(f"   Effective batch size: {training_config['per_device_train_batch_size'] * training_config['gradient_accumulation_steps']}")
    print(f"   Warmup ratio:         {training_config['warmup_ratio']}")
    print(f"   FP16:                 {training_config['fp16']}")
    print(f"   Prefetch factor:      {training_config.get('dataloader_prefetch_factor', 2)}")
    print(f"   Output directory:     {output_dir}")
    
    # =====================================================================
    # 8. OVERSAMPLING - TEMPORARILY DISABLED
    # =====================================================================
    print(f"\n{'='*70}")
    print("‚ö†Ô∏è  OVERSAMPLING TEMPORARILY DISABLED - S·ª≠ d·ª•ng d·ªØ li·ªáu g·ªëc")
    print(f"{'='*70}")
    
    # L∆∞u class counts g·ªëc ƒë·ªÉ t√≠nh Focal Loss alpha weights
    from collections import Counter
    class_counts_original = Counter(train_df['sentiment'])  # D√πng cho Focal Loss
    
    # L∆∞u train_df g·ªëc ƒë·ªÉ visualization sau n√†y
    # train_df_original = train_df.copy()  # DISABLED - kh√¥ng c·∫ßn v√¨ kh√¥ng oversample
    
    # from oversampling_utils import aspect_wise_oversample  # DISABLED
    
    # In ph√¢n b·ªë class trong training data
    print(f"\nüìä Training Data Distribution (ORIGINAL - NO OVERSAMPLING):")
    total_samples = len(train_df)
    for sentiment, count in sorted(class_counts_original.items()):
        pct = (count / total_samples) * 100
        print(f"   {sentiment:10}: {count:6,} samples ({pct:5.2f}%)")
    
    # ======================================================================
    # OVERSAMPLING CODE - COMMENTED OUT (TEMPORARILY DISABLED)
    # ======================================================================
    # Apply aspect-wise oversampling
    # V·ªõi m·ªói aspect (Battery, Camera, etc.):
    #   - T√¨m sentiment c√≥ nhi·ªÅu m·∫´u nh·∫•t
    #   - Oversample c√°c sentiment kh√°c ƒë·ªÉ b·∫±ng v·ªõi sentiment l·ªõn nh·∫•t ƒë√≥
    # print(f"\nüéØ Chi·∫øn l∆∞·ª£c: C√¢n b·∫±ng sentiment cho t·ª´ng aspect ri√™ng bi·ªát")
    
    # train_df_oversampled = aspect_wise_oversample(
    #     train_df, 
    #     aspect_column='aspect',
    #     sentiment_column='sentiment',
    #     random_state=config['reproducibility']['oversampling_seed']
    # )
    
    # Use oversampled data
    # train_df = train_df_oversampled
    
    # Recreate train_dataset with oversampled data
    # print(f"\nüîÑ Recreating train_dataset with oversampled data...")
    # train_dataset = ABSADataset(train_df, tokenizer, max_length)
    print(f"\n‚úì S·ª≠ d·ª•ng train dataset g·ªëc (kh√¥ng oversampling): {len(train_dataset):,} samples")
    
    # L∆∞u th√¥ng tin oversampling ƒë·ªÉ visualization
    # DISABLED - Kh√¥ng l∆∞u th√¥ng tin oversampling v√¨ ƒëang t·∫Øt oversampling
    # print(f"\nüíæ L∆∞u th√¥ng tin oversampling ƒë·ªÉ visualization...")
    # import json
    # from datetime import datetime
    # 
    # oversampling_info = {
    #     'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
    #     'strategy': 'aspect_wise_oversampling',
    #     'description': 'C√¢n b·∫±ng sentiment cho t·ª´ng aspect ri√™ng bi·ªát',
    #     'before': {
    #         'total_samples': len(train_df_original),
    #         'sentiment_distribution': dict(class_counts_original),
    #         'aspects': {}
    #     },
    #     'after': {
    #         'total_samples': len(train_df),
    #         'sentiment_distribution': dict(Counter(train_df['sentiment'])),
    #         'aspects': {}
    #     }
    # }
    # 
    # # L∆∞u ph√¢n b·ªë chi ti·∫øt theo aspect (before)
    # for aspect in train_df_original['aspect'].unique():
    #     aspect_data = train_df_original[train_df_original['aspect'] == aspect]
    #     oversampling_info['before']['aspects'][aspect] = dict(Counter(aspect_data['sentiment']))
    # 
    # # L∆∞u ph√¢n b·ªë chi ti·∫øt theo aspect (after)
    # for aspect in train_df['aspect'].unique():
    #     aspect_data = train_df[train_df['aspect'] == aspect]
    #     oversampling_info['after']['aspects'][aspect] = dict(Counter(aspect_data['sentiment']))
    # 
    # # L∆∞u v√†o file JSON
    # os.makedirs('analysis_results', exist_ok=True)
    # oversampling_info_path = 'analysis_results/oversampling_info.json'
    # with open(oversampling_info_path, 'w', encoding='utf-8') as f:
    #     json.dump(oversampling_info, f, indent=2, ensure_ascii=False)
    # 
    # print(f"‚úì ƒê√£ l∆∞u th√¥ng tin oversampling: {oversampling_info_path}")
    
    # =====================================================================
    # 9. T√çNH CLASS WEIGHTS V√Ä KH·ªûI T·∫†O FOCAL LOSS
    # =====================================================================
    print(f"\n{'='*70}")
    print("üî• ƒêang t√≠nh class weights cho Focal Loss...")
    print(f"{'='*70}")
    
    # T√≠nh ph√¢n b·ªë classes trong training data
    label_counts = class_counts_original
    total = sum(label_counts.values())
    
    # Class distribution
    print(f"\nüìä Ph√¢n b·ªë classes trong training data:")
    for label in ['positive', 'negative', 'neutral']:
        count = label_counts.get(label, 0)
        pct = (count / total) * 100
        print(f"   {label:10}: {count:6,} samples ({pct:5.2f}%)")
    
    # Import Focal Loss
    from utils import FocalLoss
    from focal_loss_trainer import CustomTrainer
    
    label_map = config['sentiment_labels']  # {'positive': 0, 'negative': 1, 'neutral': 2}
    
    # Read focal_alpha from config
    focal_config = config.get('single_label', {})
    focal_alpha_config = focal_config.get('focal_alpha', 'auto')
    gamma = focal_config.get('focal_gamma', 2.0)
    
    # Determine alpha weights based on config
    if focal_alpha_config == 'auto':
        # Auto: T√≠nh t·ª´ inverse frequency
        print(f"\nüéØ Alpha weights mode: AUTO (inverse frequency)")
        alpha = [0.0, 0.0, 0.0]
        for label, idx in label_map.items():
            count = label_counts.get(label, 1)
            alpha[idx] = total / (len(label_map) * count)
        
        print(f"\n   Calculated alpha weights:")
        for label, idx in label_map.items():
            print(f"   {label:10} (class {idx}): {alpha[idx]:.4f}")
    
    elif isinstance(focal_alpha_config, list) and len(focal_alpha_config) == 3:
        # User-defined weights
        print(f"\nüéØ Alpha weights mode: USER-DEFINED")
        alpha = focal_alpha_config
        print(f"\n   Using custom alpha weights:")
        for label, idx in label_map.items():
            print(f"   {label:10} (class {idx}): {alpha[idx]:.4f}")
    
    elif focal_alpha_config is None:
        # Equal weights (no class weighting)
        print(f"\nüéØ Alpha weights mode: EQUAL (no class weighting)")
        alpha = [1.0, 1.0, 1.0]
        print(f"\n   Using equal weights: {alpha}")
    
    else:
        # Invalid config, fallback to auto
        print(f"\n‚ö†Ô∏è  Invalid focal_alpha config: {focal_alpha_config}")
        print(f"   Falling back to AUTO (inverse frequency)")
        alpha = [0.0, 0.0, 0.0]
        for label, idx in label_map.items():
            count = label_counts.get(label, 1)
            alpha[idx] = total / (len(label_map) * count)
    
    # Create Focal Loss
    focal_loss = FocalLoss(alpha=alpha, gamma=gamma)
    print(f"\n‚úì Focal Loss created:")
    print(f"   Gamma: {gamma} (focusing parameter)")
    print(f"   Alpha: {alpha}")
    print(f"‚úì Focal Loss s·∫Ω focus v√†o hard examples v√† handle class imbalance")
    
    # =====================================================================
    # 10. KH·ªûI T·∫†O TRAINER V·ªöI FOCAL LOSS
    # =====================================================================
    print(f"\n{'='*70}")
    print("üèãÔ∏è  ƒêang kh·ªüi t·∫°o Custom Trainer v·ªõi Focal Loss...")
    print(f"{'='*70}")
    
    trainer = CustomTrainer.create_trainer_with_focal_loss(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        tokenizer=tokenizer,
        compute_metrics=compute_metrics,
        focal_loss=focal_loss
    )
    
    print(f"‚úì Custom Trainer v·ªõi Focal Loss ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng")
    print(f"‚úì Chi·∫øn l∆∞·ª£c x·ª≠ l√Ω class imbalance:")
    print(f"   ‚Ä¢ Focal Loss: TƒÉng tr·ªçng s·ªë loss cho minority classes")
    print(f"   ‚Ä¢ Alpha weights ƒë∆∞·ª£c t√≠nh d·ª±a tr√™n inverse frequency c·ªßa m·ªói class")
    
    # =====================================================================
    # 10.5. ADD CHECKPOINT RENAMER CALLBACK
    # =====================================================================
    print(f"\nüìÅ ƒêang thi·∫øt l·∫≠p Checkpoint Renamer...")
    
    from checkpoint_renamer import SimpleMetricCheckpointCallback
    
    # Add callback ƒë·ªÉ rename checkpoints theo accuracy
    # Example: checkpoint-1352 ‚Üí checkpoint-91 (91% accuracy)
    checkpoint_callback = SimpleMetricCheckpointCallback(metric_name='eval_accuracy')
    trainer.add_callback(checkpoint_callback)
    
    # Add Early Stopping callback ƒë·ªÉ tr√°nh overfitting
    early_stopping_callback = EarlyStoppingCallback(
        early_stopping_patience=training_config.get('early_stopping_patience', 2),
        early_stopping_threshold=training_config.get('early_stopping_threshold', 0.001)
    )
    trainer.add_callback(early_stopping_callback)
    
    print(f"‚úì Checkpoints s·∫Ω ƒë∆∞·ª£c ƒë·∫∑t t√™n theo accuracy (vd: checkpoint-90, checkpoint-92)")
    print(f"‚úì Early Stopping: s·∫Ω d·ª´ng n·∫øu eval_loss kh√¥ng c·∫£i thi·ªán sau {training_config.get('early_stopping_patience', 2)} epoch")
    
    # =====================================================================
    # 11. B·∫ÆT ƒê·∫¶U HU·∫§N LUY·ªÜN
    # =====================================================================
    print(f"\n{'='*70}")
    print("üéØ B·∫ÆT ƒê·∫¶U HU·∫§N LUY·ªÜN")
    print(f"{'='*70}\n")
    
    try:
        train_result = trainer.train()
        
        print(f"\n{'='*70}")
        print("‚úÖ HO√ÄN T·∫§T HU·∫§N LUY·ªÜN")
        print(f"{'='*70}")
        print(f"‚úì Training loss: {train_result.training_loss:.4f}")
        print(f"‚úì Training time: {train_result.metrics['train_runtime']:.2f}s")
        print(f"‚úì Samples/second: {train_result.metrics['train_samples_per_second']:.2f}")
        
    except Exception as e:
        print(f"\n‚ùå L·ªói trong qu√° tr√¨nh hu·∫•n luy·ªán: {str(e)}")
        return
    
    # =====================================================================
    # 9.5. T·∫†O TRAINER M·ªöI CHO EVALUATION (KH√îNG C√ì OPTIMIZER)
    # =====================================================================
    print(f"\n{'='*70}")
    print("üîÑ T·∫†O TRAINER M·ªöI CHO EVALUATION")
    print(f"{'='*70}")
    
    # L∆∞u model hi·ªán t·∫°i
    current_model = trainer.model
    
    # X√≥a trainer c≈© (c√≥ optimizer/scheduler)
    del trainer
    torch.cuda.empty_cache()
    
    # T·∫°o trainer m·ªõi ch·ªâ ƒë·ªÉ eval (kh√¥ng c√≥ optimizer/scheduler)
    eval_trainer = Trainer(
        model=current_model,
        args=training_args,
        eval_dataset=val_dataset,
        processing_class=tokenizer,
        compute_metrics=compute_metrics
    )
    
    print(f"‚úì ƒê√£ t·∫°o trainer m·ªõi cho evaluation (kh√¥ng c√≥ optimizer/scheduler)")
    print(f"‚úì VRAM ƒë√£ gi·∫£m, s·∫µn s√†ng cho evaluation")
    
    # =====================================================================
    # 10. ƒê√ÅNH GI√Å TR√äN T·∫¨P TEST
    # =====================================================================
    print(f"\n{'='*70}")
    print("üìä ƒê√ÅNH GI√Å TR√äN T·∫¨P TEST")
    print(f"{'='*70}")
    
    try:
        # Evaluate
        print("‚è≥ ƒêang evaluate tr√™n test dataset...")
        test_results = eval_trainer.evaluate(test_dataset)
        
        print(f"\n‚úì K·∫øt qu·∫£ ƒë√°nh gi√° tr√™n t·∫≠p test:")
        print(f"   Accuracy:  {test_results['eval_accuracy']:.4f}")
        print(f"   Precision: {test_results['eval_precision']:.4f}")
        print(f"   Recall:    {test_results['eval_recall']:.4f}")
        print(f"   F1 Score:  {test_results['eval_f1']:.4f}")
        
        # Gi·∫£i ph√≥ng cache tr∆∞·ªõc khi predict ƒë·ªÉ tr√°nh OOM
        torch.cuda.empty_cache()
        
        # L·∫•y detailed metrics
        # CH√ö √ù: Ch·ªâ predict 1 L·∫¶N DUY NH·∫§T ·ªü ƒë√¢y, sau ƒë√≥ t√°i s·ª≠ d·ª•ng cho save_predictions
        print("\n‚è≥ ƒêang predict ƒë·ªÉ l·∫•y detailed metrics...")
        predictions_output = eval_trainer.predict(test_dataset)
        print("‚úì Predict ho√†n t·∫•t")
        label_names = [id2label[i] for i in sorted(id2label.keys())]
        detailed_report = get_detailed_metrics(
            predictions_output.predictions,
            predictions_output.label_ids,
            label_names
        )
        
        print(f"\n‚úì B√°o c√°o chi ti·∫øt theo t·ª´ng class:")
        print(detailed_report)
        
        # L∆∞u b√°o c√°o v√†o file
        report_path = config['paths']['evaluation_report']
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("="*70 + "\n")
            f.write("B√ÅO C√ÅO ƒê√ÅNH GI√Å M√î H√åNH ABSA\n")
            f.write("="*70 + "\n\n")
            
            f.write("T·ªïng quan:\n")
            f.write(f"  Accuracy:  {test_results['eval_accuracy']:.4f}\n")
            f.write(f"  Precision: {test_results['eval_precision']:.4f}\n")
            f.write(f"  Recall:    {test_results['eval_recall']:.4f}\n")
            f.write(f"  F1 Score:  {test_results['eval_f1']:.4f}\n\n")
            
            f.write("B√°o c√°o chi ti·∫øt theo t·ª´ng class:\n")
            f.write(detailed_report)
            
            f.write("\n" + "="*70 + "\n")
            f.write("C·∫•u h√¨nh m√¥ h√¨nh:\n")
            f.write(f"  Model: {model_name}\n")
            f.write(f"  Epochs: {training_config['num_train_epochs']}\n")
            f.write(f"  Learning rate: {training_config['learning_rate']}\n")
            f.write(f"  Batch size: {training_config['per_device_train_batch_size']}\n")
            f.write(f"  Max length: {max_length}\n")
        
        print(f"\n‚úì ƒê√£ l∆∞u b√°o c√°o chi ti·∫øt v√†o: {report_path}")
        
    except Exception as e:
        print(f"\n‚ùå L·ªói khi ƒë√°nh gi√°: {str(e)}")
        import traceback
        traceback.print_exc()
        return
    
    # =====================================================================
    # 11. L∆ØU K·∫æT QU·∫¢ D·ª∞ ƒêO√ÅN
    # =====================================================================
    try:
        # T√°i s·ª≠ d·ª•ng predictions_output ƒë√£ c√≥ t·ª´ b∆∞·ªõc tr∆∞·ªõc (tr√°nh predict 2 l·∫ßn)
        save_predictions_from_output(predictions_output, test_df, config, id2label)
        
        # ALSO save to standard filename for analysis scripts
        predictions_standard_path = "test_predictions.csv"
        if config['paths']['predictions_file'] != predictions_standard_path:
            import shutil
            shutil.copy(config['paths']['predictions_file'], predictions_standard_path)
            print(f"‚úì ƒê√£ copy predictions sang: {predictions_standard_path}")
    except Exception as e:
        print(f"\n‚ö†Ô∏è  C·∫£nh b√°o: Kh√¥ng th·ªÉ l∆∞u predictions: {str(e)}")
    
    # =====================================================================
    # 12. L∆ØU M√î H√åNH V√Ä TOKENIZER
    # =====================================================================
    print(f"\n{'='*70}")
    print("üíæ ƒêang l∆∞u m√¥ h√¨nh v√† tokenizer...")
    print(f"{'='*70}")
    
    try:
        # load_best_model_at_end=True ch·ªâ load best model v√†o memory
        # Ph·∫£i g·ªçi save_model() ƒë·ªÉ l∆∞u ra disk
        final_model_dir = output_dir
        
        # Save best model (d√πng eval_trainer thay v√¨ trainer ƒë√£ b·ªã x√≥a)
        eval_trainer.save_model(final_model_dir)
        tokenizer.save_pretrained(final_model_dir)
        
        print(f"\n‚úì M√¥ h√¨nh v√† tokenizer ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {final_model_dir}")
        print(f"‚úì B·∫°n c√≥ th·ªÉ load l·∫°i b·∫±ng:")
        print(f"   tokenizer = AutoTokenizer.from_pretrained('{final_model_dir}')")
        print(f"   model = AutoModelForSequenceClassification.from_pretrained('{final_model_dir}')")
        
    except Exception as e:
        print(f"\n‚ö†Ô∏è  C·∫£nh b√°o: Kh√¥ng th·ªÉ l∆∞u m√¥ h√¨nh: {str(e)}")
        import traceback
        traceback.print_exc()
    
    # =====================================================================
    # 12.5. GI·∫¢I PH√ìNG GPU MEMORY TR∆Ø·ªöC ANALYSIS
    # =====================================================================
    print(f"\n{'='*70}")
    print("üßπ GI·∫¢I PH√ìNG GPU MEMORY")
    print(f"{'='*70}")
    
    # X√≥a eval_trainer v√† model sau khi ƒë√£ save xong
    del eval_trainer
    del current_model
    torch.cuda.empty_cache()
    
    print(f"‚úì ƒê√£ gi·∫£i ph√≥ng GPU memory")
    
    # =====================================================================
    # 13. T·ª∞ ƒê·ªòNG PH√ÇN T√çCH K·∫æT QU·∫¢
    # =====================================================================
    print(f"\n{'='*70}")
    print("üìä T·ª∞ ƒê·ªòNG PH√ÇN T√çCH K·∫æT QU·∫¢ CHI TI·∫æT")
    print(f"{'='*70}")
    
    try:
        # Import v√† ch·∫°y analyze_results
        import analyze_results
        
        print("‚úì ƒêang ch·∫°y ph√¢n t√≠ch chi ti·∫øt...")
        analyze_results.main()
        
    except Exception as e:
        print(f"\n‚ö†Ô∏è  C·∫£nh b√°o: Kh√¥ng th·ªÉ t·ª± ƒë·ªông ph√¢n t√≠ch: {str(e)}")
        print(f"   B·∫°n c√≥ th·ªÉ ch·∫°y th·ªß c√¥ng: python analyze_results.py")
    
    # =====================================================================
    # 14. K·∫æT TH√öC
    # =====================================================================
    print(f"\n{'='*70}")
    print("üéâ HO√ÄN T·∫§T TO√ÄN B·ªò QU√Å TR√åNH!")
    print(f"{'='*70}")
    
    print(f"\n‚úì T·ªïng k·∫øt:")
    print(f"   ‚Ä¢ M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c fine-tune th√†nh c√¥ng")
    print(f"   ‚Ä¢ F1 Score tr√™n test: {test_results['eval_f1']:.4f}")
    print(f"   ‚Ä¢ M√¥ h√¨nh ƒë∆∞·ª£c l∆∞u t·∫°i: {output_dir}")
    print(f"   ‚Ä¢ B√°o c√°o ƒë√°nh gi√°: {config['paths']['evaluation_report']}")
    print(f"   ‚Ä¢ Predictions: {config['paths']['predictions_file']}")
    print(f"   ‚Ä¢ Ph√¢n t√≠ch chi ti·∫øt: analysis_results/")
    
    print(f"\n‚úì C·∫£m ∆°n b·∫°n ƒë√£ s·ª≠ d·ª•ng! üôè\n")
    
    # =====================================================================
    # ƒê√ìNG LOGGER V√Ä RESTORE STDOUT/STDERR
    # =====================================================================
    print(f"\nüìù Training log ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {log_file_path}")
    
    # Restore stdout/stderr v√† ƒë√≥ng file log
    sys.stdout = tee_logger.terminal
    sys.stderr = tee_logger.terminal
    tee_logger.close()


if __name__ == '__main__':
    main()
