"""
Script VÃ­ Dá»¥ Dá»± ÄoÃ¡n ABSA
=========================
Demo cÃ¡ch sá»­ dá»¥ng mÃ´ hÃ¬nh Ä‘Ã£ fine-tune Ä‘á»ƒ dá»± Ä‘oÃ¡n sentiment cho aspect trong cÃ¢u má»›i

Usage:
    python predict_example.py
"""

import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification


def predict_sentiment(model, tokenizer, sentence, aspect, device='cpu'):
    """
    Dá»± Ä‘oÃ¡n sentiment cho má»™t cáº·p (sentence, aspect)
    
    Args:
        model: MÃ´ hÃ¬nh Ä‘Ã£ fine-tune
        tokenizer: Tokenizer
        sentence: CÃ¢u vÄƒn
        aspect: KhÃ­a cáº¡nh cáº§n phÃ¢n tÃ­ch
        device: 'cuda' hoáº·c 'cpu'
        
    Returns:
        tuple: (predicted_sentiment, confidence_score)
    """
    # Label mapping
    id2label = {
        0: 'positive',
        1: 'negative',
        2: 'neutral'
    }
    
    # Xá»­ lÃ½ VNCoreNLP segmentation náº¿u cÃ³
    sentence = sentence.replace('_', ' ')
    
    # Tokenize input
    inputs = tokenizer(
        sentence,
        aspect,
        return_tensors='pt',
        max_length=256,
        truncation=True,
        padding=True
    )
    
    # Di chuyá»ƒn inputs sang device
    inputs = {k: v.to(device) for k, v in inputs.items()}
    
    # Dá»± Ä‘oÃ¡n
    model.eval()
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        probs = torch.softmax(logits, dim=-1)
        predicted_class = torch.argmax(probs, dim=-1).item()
        confidence = probs[0][predicted_class].item()
    
    predicted_sentiment = id2label[predicted_class]
    
    return predicted_sentiment, confidence


def main():
    """HÃ m main"""
    print("\n" + "="*70)
    print("Dá»° ÄOÃN ABSA Vá»šI VISOBERT")
    print("="*70)
    
    # ÄÆ°á»ng dáº«n Ä‘áº¿n mÃ´ hÃ¬nh Ä‘Ã£ fine-tune
    model_path = "finetuned_visobert_absa_model"
    
    # Kiá»ƒm tra device
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"\nâœ“ Device: {device}")
    
    # Load mÃ´ hÃ¬nh vÃ  tokenizer
    print(f"\nâœ“ Äang load mÃ´ hÃ¬nh tá»«: {model_path}")
    try:
        tokenizer = AutoTokenizer.from_pretrained(model_path)
        model = AutoModelForSequenceClassification.from_pretrained(model_path)
        model.to(device)
        print(f"âœ“ Load mÃ´ hÃ¬nh thÃ nh cÃ´ng!")
    except Exception as e:
        print(f"\nâŒ Lá»—i: {str(e)}")
        print(f"\nGá»£i Ã½: HÃ£y cháº¡y 'python train.py' Ä‘á»ƒ fine-tune mÃ´ hÃ¬nh trÆ°á»›c")
        return
    
    # CÃ¡c vÃ­ dá»¥ test
    test_examples = [
        {
            'sentence': 'Pin trÃ¢u láº¯m, dÃ¹ng cáº£ ngÃ y khÃ´ng lo háº¿t pin. Camera chá»¥p hÆ¡i tá»‘i.',
            'aspects': ['Battery', 'Camera']
        },
        {
            'sentence': 'MÃ n hÃ¬nh Ä‘áº¹p, hiá»ƒn thá»‹ sáº¯c nÃ©t. Hiá»‡u nÄƒng mÆ°á»£t mÃ , chÆ¡i game khÃ´ng lag.',
            'aspects': ['Display', 'Performance']
        },
        {
            'sentence': 'GiÃ¡ hÆ¡i cao so vá»›i máº·t báº±ng chung. Thiáº¿t káº¿ Ä‘áº¹p, sang trá»ng.',
            'aspects': ['Price', 'Design']
        },
        {
            'sentence': 'Giao hÃ ng nhanh, Ä‘Ã³ng gÃ³i cáº©n tháº­n. Shop tÆ° váº¥n nhiá»‡t tÃ¬nh.',
            'aspects': ['Shipping', 'Packaging', 'Shop_Service']
        }
    ]
    
    print(f"\n{'='*70}")
    print("Káº¾T QUáº¢ Dá»° ÄOÃN")
    print(f"{'='*70}\n")
    
    # Dá»± Ä‘oÃ¡n cho tá»«ng vÃ­ dá»¥
    for idx, example in enumerate(test_examples, 1):
        sentence = example['sentence']
        aspects = example['aspects']
        
        print(f"VÃ­ dá»¥ {idx}:")
        print(f"CÃ¢u: {sentence}\n")
        
        for aspect in aspects:
            sentiment, confidence = predict_sentiment(
                model, tokenizer, sentence, aspect, device
            )
            
            # Biá»ƒu tÆ°á»£ng cho sentiment
            emoji_map = {
                'positive': 'ğŸ˜Š',
                'negative': 'ğŸ˜',
                'neutral': 'ğŸ˜'
            }
            emoji = emoji_map.get(sentiment, '')
            
            print(f"  â€¢ {aspect:>15}: {emoji} {sentiment:>10} (confidence: {confidence:.2%})")
        
        print()
    
    # Interactive mode
    print(f"{'='*70}")
    print("CHáº¾ Äá»˜ TÆ¯Æ NG TÃC")
    print(f"{'='*70}\n")
    print("Nháº­p cÃ¢u vÃ  aspect Ä‘á»ƒ dá»± Ä‘oÃ¡n (hoáº·c 'quit' Ä‘á»ƒ thoÃ¡t)\n")
    
    while True:
        try:
            sentence = input("CÃ¢u: ").strip()
            if sentence.lower() in ['quit', 'exit', 'q']:
                break
            
            if not sentence:
                continue
            
            aspect = input("Aspect: ").strip()
            if not aspect:
                continue
            
            sentiment, confidence = predict_sentiment(
                model, tokenizer, sentence, aspect, device
            )
            
            emoji_map = {
                'positive': 'ğŸ˜Š',
                'negative': 'ğŸ˜',
                'neutral': 'ğŸ˜'
            }
            emoji = emoji_map.get(sentiment, '')
            
            print(f"\nâ†’ Káº¿t quáº£: {emoji} {sentiment.upper()} (confidence: {confidence:.2%})\n")
            print("-" * 70 + "\n")
            
        except KeyboardInterrupt:
            print("\n\nThoÃ¡t chÆ°Æ¡ng trÃ¬nh.")
            break
        except Exception as e:
            print(f"\nâŒ Lá»—i: {str(e)}\n")
    
    print("\n" + "="*70)
    print("Cáº£m Æ¡n báº¡n Ä‘Ã£ sá»­ dá»¥ng! ğŸ‘‹")
    print("="*70 + "\n")


if __name__ == '__main__':
    # Fix encoding cho Windows
    import sys
    import io
    
    if sys.platform == 'win32':
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')
    
    main()
