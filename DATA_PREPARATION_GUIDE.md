# ğŸ“Š Data Preparation Guide

## ğŸ¯ Overview

Dá»± Ã¡n cÃ³ 2 approaches vá»›i data formats khÃ¡c nhau:

```
Single-Label:  One row per (sentence, aspect) pair
Multi-Label:   One row per sentence (all aspects as columns)
```

Má»—i approach cÃ³ data folder riÃªng vÃ  scripts riÃªng.

---

## ğŸ“‚ Folder Structure

```
D:\BERT\
â”œâ”€â”€ dataset.csv                       (Original multi-label format)
â”‚
â”œâ”€â”€ single_label/
â”‚   â”œâ”€â”€ data/                         Single-label data folder
â”‚   â”‚   â”œâ”€â”€ train.csv
â”‚   â”‚   â”œâ”€â”€ validation.csv
â”‚   â”‚   â”œâ”€â”€ test.csv
â”‚   â”‚   â”œâ”€â”€ train_augmented_neutral_nhung.csv
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ prepare_data.py               Convert to single-label
â”‚   â”œâ”€â”€ augment_neutral_and_nhung.py  Augment data
â”‚   â””â”€â”€ prepare_and_augment.bat       Quick start script
â”‚
â””â”€â”€ multi_label/
    â”œâ”€â”€ data/                         Multi-label data folder
    â”‚   â”œâ”€â”€ train_multilabel.csv
    â”‚   â”œâ”€â”€ validation_multilabel.csv
    â”‚   â”œâ”€â”€ test_multilabel.csv
    â”‚   â”œâ”€â”€ train_multilabel_balanced.csv
    â”‚   â””â”€â”€ README.md
    â”œâ”€â”€ prepare_data_multilabel.py    Split dataset
    â”œâ”€â”€ augment_multilabel_balanced.py Balance data
    â””â”€â”€ prepare_and_augment.bat       Quick start script
```

---

## ğŸ”§ Single-Label Data Preparation

### **Manual Steps:**

**Step 1: Prepare Data**
```bash
# From D:\BERT\
python single_label/prepare_data.py
```
**Output:** `single_label/data/train.csv`, `validation.csv`, `test.csv`

**Step 2: Augment Data**
```bash
python single_label/augment_neutral_and_nhung.py
```
**Output:** `single_label/data/train_augmented_neutral_nhung.csv`

### **Quick Start (Recommended):**

```bash
# From D:\BERT\
single_label\prepare_and_augment.bat
```

**This will automatically:**
1. Convert dataset.csv to single-label format
2. Split into train/val/test (80/10/10)
3. Apply Neutral + "nhÆ°ng" augmentation
4. Create `train_augmented_neutral_nhung.csv`

### **Data Format:**

```csv
sentence,aspect,sentiment
"Pin tá»‘t camera xáº¥u",Battery,positive
"Pin tá»‘t camera xáº¥u",Camera,negative
"Pin tá»‘t camera xáº¥u",Performance,neutral
```

### **Augmentation Strategy:**

1. **Neutral Oversampling:** Balance Neutral with avg(Positive, Negative)
2. **"NhÆ°ng" Oversampling:** x3 factor for adversative constructions
3. **Overlap Handling:** Intelligent handling of samples with both

**Expected Result:** ~10,000-12,000 training samples

---

## ğŸ”§ Multi-Label Data Preparation

### **Manual Steps:**

**Step 1: Prepare Data**
```bash
# From D:\BERT\
python multi_label/prepare_data_multilabel.py
```
**Output:** `multi_label/data/train_multilabel.csv`, `validation_multilabel.csv`, `test_multilabel.csv`

**Step 2: Balance Data**
```bash
python multi_label/augment_multilabel_balanced.py
```
**Output:** `multi_label/data/train_multilabel_balanced.csv`

### **Quick Start (Recommended):**

```bash
# From D:\BERT\
multi_label\prepare_and_augment.bat
```

**This will automatically:**
1. Split dataset.csv into train/val/test (80/10/10)
2. Apply aspect-wise balanced oversampling
3. Create `train_multilabel_balanced.csv`

### **Data Format:**

```csv
text,Battery,Camera,Performance,Display,...
"Pin tá»‘t camera xáº¥u",Positive,Negative,Neutral,...
```

### **Balancing Strategy:**

**Aspect-wise Oversampling:**
- For each aspect: oversample minority sentiments to match majority
- Example: Battery has Negative=500, Positive=200, Neutral=100
  â†’ Oversample Positive and Neutral to 500 each

**Result:**
- Original: 7,309 samples
- Balanced: 15,921 samples (+117.8%)
- Imbalance: 5.30x â†’ 1.22x (77% improvement)

---

## ğŸ“Š Comparison

| Feature | Single-Label | Multi-Label |
|---------|-------------|-------------|
| **Format** | One row per (sentence, aspect) | One row per sentence |
| **Original Size** | ~80,000 samples | ~7,309 samples |
| **After Augmentation** | ~12,000 samples | ~15,921 samples |
| **Augmentation** | Neutral + "nhÆ°ng" | Aspect-wise balancing |
| **Training Time** | Longer (more samples) | Faster (fewer samples) |
| **Inference** | 11 forward passes | 1 forward pass |
| **Expected F1** | ~93% | ~96% |

---

## ğŸš€ Complete Workflow

### **For Single-Label:**

```bash
# 1. Prepare data
cd D:\BERT
single_label\prepare_and_augment.bat

# 2. Train
python single_label\train.py --config single_label\config_single.yaml

# 3. Analyze
bash single_label/test/run_analysis.sh
```

---

### **For Multi-Label:**

```bash
# 1. Prepare data
cd D:\BERT
multi_label\prepare_and_augment.bat

# 2. Train (Target: 96% F1)
python multi_label\train_multilabel_focal_contrastive.py --epochs 8 --focal-weight 0.7 --contrastive-weight 0.3

# Or quick start:
train_focal_contrastive.bat

# 3. Analyze
bash multi_label/test/run_analysis.sh
```

---

## ğŸ“ Generated Files

### **Single-Label:**
```
single_label/data/
â”œâ”€â”€ train.csv                              (~6,500 samples)
â”œâ”€â”€ validation.csv                         (~800 samples)
â”œâ”€â”€ test.csv                               (~800 samples)
â”œâ”€â”€ train_augmented_neutral_nhung.csv      (~12,000 samples) â­
â””â”€â”€ data_metadata.json
```

### **Multi-Label:**
```
multi_label/data/
â”œâ”€â”€ train_multilabel.csv                   (7,309 samples)
â”œâ”€â”€ validation_multilabel.csv              (914 samples)
â”œâ”€â”€ test_multilabel.csv                    (914 samples)
â”œâ”€â”€ train_multilabel_balanced.csv          (15,921 samples) â­
â””â”€â”€ multilabel_metadata.json
```

**â­ = Recommended for training**

---

## âš™ï¸ Configuration

### **Single-Label Config:**
```yaml
# single_label/config_single.yaml
paths:
  train_file: "single_label/data/train_augmented_neutral_nhung.csv"
  validation_file: "single_label/data/validation.csv"
  test_file: "single_label/data/test.csv"
```

### **Multi-Label Config:**
```yaml
# multi_label/config_multi.yaml
paths:
  train_file: "multi_label/data/train_multilabel_balanced.csv"
  validation_file: "multi_label/data/validation_multilabel.csv"
  test_file: "multi_label/data/test_multilabel.csv"
```

---

## ğŸ” Troubleshooting

### **Problem: Data folders empty**

**Solution:**
```bash
# Single-label
single_label\prepare_and_augment.bat

# Multi-label
multi_label\prepare_and_augment.bat
```

### **Problem: Need to regenerate data**

**Solution:**
```bash
# Delete old files
rm single_label/data/*.csv
rm multi_label/data/*_multilabel*.csv

# Regenerate
single_label\prepare_and_augment.bat
multi_label\prepare_and_augment.bat
```

### **Problem: Training fails with file not found**

**Check:**
1. Run data preparation scripts first
2. Verify paths in config files
3. Make sure you're running from `D:\BERT\` directory

---

## âœ… Quick Checklist

### **Before Training Single-Label:**
- [ ] `single_label/data/train_augmented_neutral_nhung.csv` exists
- [ ] `single_label/data/validation.csv` exists
- [ ] `single_label/data/test.csv` exists
- [ ] Config points to correct files

### **Before Training Multi-Label:**
- [ ] `multi_label/data/train_multilabel_balanced.csv` exists
- [ ] `multi_label/data/validation_multilabel.csv` exists
- [ ] `multi_label/data/test_multilabel.csv` exists
- [ ] Config points to correct files

---

## ğŸ“ Notes

- **Always run from root:** All scripts should be run from `D:\BERT\` directory
- **Separate data:** Single-label and multi-label use completely different formats
- **Augmentation recommended:** Both approaches benefit from data augmentation
- **Configs already set:** Default configs point to augmented data files
- **Quick start scripts:** Use `.bat` files for automatic preparation

---

## ğŸ¯ Summary

| Approach | Quick Start Command | Expected F1 |
|----------|-------------------|-------------|
| Single-Label | `single_label\prepare_and_augment.bat` | 93% |
| Multi-Label | `multi_label\prepare_and_augment.bat` | 96% |

**Recommendation:** Use multi-label approach for better performance! ğŸš€
