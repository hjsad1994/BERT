# Giáº£i ThÃ­ch CÃ¡c Metrics vÃ  Loss Functions

HÆ°á»›ng dáº«n chi tiáº¿t vá» cÃ¡c chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ model trong Machine Learning

---

## ğŸ“Š 1. CÃC METRICS CÆ  Báº¢N

### ğŸ¯ **Confusion Matrix (Ma Tráº­n Nháº§m Láº«n)**

ÄÃ¢y lÃ  ná»n táº£ng Ä‘á»ƒ tÃ­nh táº¥t cáº£ metrics khÃ¡c:

```
                    Dá»± Ä‘oÃ¡n
                Positive  Negative
Thá»±c táº¿  Pos  |   TP    |   FN    |
         Neg  |   FP    |   TN    |
```

**Giáº£i thÃ­ch:**
- **TP (True Positive)**: Dá»± Ä‘oÃ¡n Positive, thá»±c táº¿ Positive âœ…
- **TN (True Negative)**: Dá»± Ä‘oÃ¡n Negative, thá»±c táº¿ Negative âœ…
- **FP (False Positive)**: Dá»± Ä‘oÃ¡n Positive, thá»±c táº¿ Negative âŒ (Type I Error)
- **FN (False Negative)**: Dá»± Ä‘oÃ¡n Negative, thá»±c táº¿ Positive âŒ (Type II Error)

---

### ğŸ“ˆ **Accuracy (Äá»™ ChÃ­nh XÃ¡c)**

**Äá»‹nh nghÄ©a:** Tá»· lá»‡ dá»± Ä‘oÃ¡n Ä‘Ãºng trÃªn tá»•ng sá»‘ dá»± Ä‘oÃ¡n

**CÃ´ng thá»©c:**
```
Accuracy = (TP + TN) / (TP + TN + FP + FN)
```

**VÃ­ dá»¥ tá»« model cá»§a báº¡n:**
```
Accuracy = 91.06% = 1834 Ä‘Ãºng / 2014 tá»•ng
```

**Khi nÃ o dÃ¹ng:**
- âœ… Classes cÃ¢n báº±ng (positive â‰ˆ negative â‰ˆ neutral)
- âŒ Classes imbalance (nhÆ° model cá»§a báº¡n: neutral chá»‰ 5%)

**Váº¥n Ä‘á»:**
```python
# VÃ­ dá»¥: 100 samples, 95 positive, 5 negative
# Model dá»± Ä‘oÃ¡n Táº¤T Cáº¢ lÃ  positive
# â†’ Accuracy = 95% (cao!)
# â†’ NhÆ°ng khÃ´ng bao giá» detect Ä‘Æ°á»£c negative! (vÃ´ dá»¥ng)
```

---

### ğŸ¯ **Precision (Äá»™ ChÃ­nh XÃ¡c Cá»§a Dá»± ÄoÃ¡n Positive)**

**Äá»‹nh nghÄ©a:** Trong nhá»¯ng cÃ¡i mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n Positive, bao nhiÃªu % thá»±c sá»± Positive?

**CÃ´ng thá»©c:**
```
Precision = TP / (TP + FP)
```

**VÃ­ dá»¥ thá»±c táº¿:**
```
Model dá»± Ä‘oÃ¡n 100 cÃ¢u lÃ  "positive"
â†’ 90 cÃ¢u thá»±c sá»± positive (TP = 90)
â†’ 10 cÃ¢u thá»±c ra negative (FP = 10)
â†’ Precision = 90/100 = 0.90 = 90%
```

**Tá»« log cá»§a báº¡n:**
```
Positive: precision=0.8934 
â†’ Khi model nÃ³i "positive", Ä‘Ãºng 89.34%
```

**Khi nÃ o quan trá»ng:**
- ğŸš¨ **Spam filter**: KhÃ´ng muá»‘n email quan trá»ng bá»‹ Ä‘Ã¡nh dáº¥u spam
- ğŸ” **Search engine**: Káº¿t quáº£ tÃ¬m kiáº¿m pháº£i chÃ­nh xÃ¡c
- âš–ï¸ **Legal**: KhÃ´ng muá»‘n buá»™c tá»™i ngÆ°á»i vÃ´ tá»™i

**CÃ¢u há»i quan trá»ng:** *"Náº¿u model nÃ³i Positive, tÃ´i cÃ³ thá»ƒ tin Ä‘Æ°á»£c khÃ´ng?"*

---

### ğŸ£ **Recall (Äá»™ Phá»§ / Kháº£ NÄƒng TÃ¬m Ra)**

**Äá»‹nh nghÄ©a:** Trong táº¥t cáº£ samples thá»±c sá»± Positive, mÃ´ hÃ¬nh tÃ¬m Ä‘Æ°á»£c bao nhiÃªu %?

**CÃ´ng thá»©c:**
```
Recall = TP / (TP + FN)
```

**VÃ­ dá»¥ thá»±c táº¿:**
```
CÃ³ 100 cÃ¢u thá»±c sá»± "positive"
â†’ Model tÃ¬m Ä‘Æ°á»£c 92 cÃ¢u (TP = 92)
â†’ Bá» sÃ³t 8 cÃ¢u (FN = 8)
â†’ Recall = 92/100 = 0.92 = 92%
```

**Tá»« log cá»§a báº¡n:**
```
Positive: recall=0.9246
â†’ Vá»›i 716 cÃ¢u positive thá»±c táº¿, model tÃ¬m Ä‘Æ°á»£c 92.46%
```

**Khi nÃ o quan trá»ng:**
- ğŸ¥ **Medical diagnosis**: KHÃ”NG Ä‘Æ°á»£c bá» sÃ³t bá»‡nh nhÃ¢n ung thÆ°
- ğŸ” **Security**: PHáº¢I phÃ¡t hiá»‡n háº¿t virus/malware
- ğŸš¨ **Fire alarm**: ThÃ  bÃ¡o Ä‘á»™ng nháº§m, khÃ´ng Ä‘Æ°á»£c bá» sÃ³t chÃ¡y tháº­t

**CÃ¢u há»i quan trá»ng:** *"Model cÃ³ bá» sÃ³t nhiá»u khÃ´ng?"*

---

### âš–ï¸ **Precision vs Recall Trade-off**

```
         HIGH PRECISION          HIGH RECALL
         (ChÃ­nh xÃ¡c)            (ToÃ n diá»‡n)
              
   Dá»± Ä‘oÃ¡n Ã­t nhÆ°ng cháº¯c    Dá»± Ä‘oÃ¡n nhiá»u Ä‘á»ƒ khÃ´ng bá» sÃ³t
              |                      |
              v                      v
        Ãt False Positive      Ãt False Negative
```

**VÃ­ dá»¥:**

**Spam Filter:**
```
High Precision (Conservative):
- Chá»‰ Ä‘Ã¡nh dáº¥u spam khi 99% cháº¯c cháº¯n
- Ãt email quan trá»ng bá»‹ nháº§m spam
- NhÆ°ng nhiá»u spam lá»t vÃ o inbox

High Recall (Aggressive):
- ÄÃ¡nh dáº¥u spam khi nghi ngá» 50%
- Báº¯t Ä‘Æ°á»£c háº§u háº¿t spam
- NhÆ°ng nhiá»u email quan trá»ng bá»‹ nháº§m spam
```

**Trade-off:**
- TÄƒng Precision â†’ Giáº£m Recall
- TÄƒng Recall â†’ Giáº£m Precision

â†’ Cáº§n **cÃ¢n báº±ng** â†’ DÃ¹ng **F1 Score**!

---

### ğŸ† **F1 Score (Harmonic Mean cá»§a Precision vÃ  Recall)**

**Äá»‹nh nghÄ©a:** Trung bÃ¬nh Ä‘iá»u hÃ²a cá»§a Precision vÃ  Recall

**CÃ´ng thá»©c:**
```
F1 = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)
```

**Táº¡i sao dÃ¹ng Harmonic Mean (khÃ´ng pháº£i Average)?**

```
VÃ­ dá»¥ 1: Precision=100%, Recall=0%
â†’ Average = (100+0)/2 = 50% (cÃ³ váº» oke?)
â†’ F1 = 2Ã—(100Ã—0)/(100+0) = 0% âœ… (pháº£n Ã¡nh Ä‘Ãºng: model vÃ´ dá»¥ng)

VÃ­ dá»¥ 2: Precision=90%, Recall=90%
â†’ Average = 90%
â†’ F1 = 2Ã—(90Ã—90)/(90+90) = 90% âœ… (cÃ¢n báº±ng tá»‘t)

VÃ­ dá»¥ 3: Precision=80%, Recall=100%
â†’ Average = 90%
â†’ F1 = 2Ã—(80Ã—100)/(180) = 88.9% (pháº¡t khi khÃ´ng cÃ¢n báº±ng)
```

**Tá»« log cá»§a báº¡n:**
```
Positive: precision=0.8934, recall=0.9246
â†’ F1 = 2Ã—(0.8934Ã—0.9246)/(0.8934+0.9246) = 0.9087

Neutral: precision=0.4766, recall=0.4811
â†’ F1 = 2Ã—(0.4766Ã—0.4811)/(0.4766+0.4811) = 0.4789 âŒ (Ráº¤T THáº¤P)
```

**Khi nÃ o dÃ¹ng:**
- âœ… Muá»‘n cÃ¢n báº±ng giá»¯a Precision vÃ  Recall
- âœ… Classes imbalance
- âœ… So sÃ¡nh models

**Giáº£i thÃ­ch Ä‘Æ¡n giáº£n:**
> F1 Score lÃ  **"Ä‘iá»ƒm trung bÃ¬nh nghiÃªm kháº¯c"** cá»§a Precision vÃ  Recall.  
> Náº¿u 1 trong 2 tháº¥p â†’ F1 tháº¥p  
> Cáº£ 2 cao â†’ F1 cao

---

## ğŸ“Š 2. MACRO vs WEIGHTED AVERAGE

### ğŸ¨ **Macro Average** (Trung BÃ¬nh ÄÆ¡n Giáº£n)

**CÃ´ng thá»©c:**
```
Macro F1 = (F1_positive + F1_negative + F1_neutral) / 3
```

**VÃ­ dá»¥ tá»« model cá»§a báº¡n:**
```
Positive F1 = 0.9087
Negative F1 = 0.9508  
Neutral F1  = 0.4789

Macro F1 = (0.9087 + 0.9508 + 0.4789) / 3 = 0.7795
```

**Äáº·c Ä‘iá»ƒm:**
- âœ… Má»—i class cÃ³ **trá»ng sá»‘ báº±ng nhau** (khÃ´ng quan tÃ¢m sá»‘ lÆ°á»£ng samples)
- âœ… PhÃ¡t hiá»‡n class yáº¿u (neutral F1=0.48 kÃ©o Macro xuá»‘ng)
- âŒ KhÃ´ng pháº£n Ã¡nh overall performance

**Khi nÃ o dÃ¹ng:**
- âœ… Má»—i class quan trá»ng nhÆ° nhau (medical: má»—i bá»‡nh Ä‘á»u quan trá»ng)
- âœ… Muá»‘n cáº£i thiá»‡n class yáº¿u
- âœ… Classes imbalance (nhÆ° báº¡n: neutral 5%, negative 59%)

**Ã nghÄ©a:**
> "MÃ´ hÃ¬nh lÃ m tá»‘t **trung bÃ¬nh** trÃªn tá»«ng class"  
> Náº¿u Macro tháº¥p â†’ cÃ³ class ráº¥t yáº¿u cáº§n cáº£i thiá»‡n

---

### âš–ï¸ **Weighted Average** (Trung BÃ¬nh CÃ³ Trá»ng Sá»‘)

**CÃ´ng thá»©c:**
```
Weighted F1 = Î£(F1_class Ã— sá»‘_samples_class) / tá»•ng_samples
```

**VÃ­ dá»¥ tá»« model cá»§a báº¡n:**
```
Positive: F1=0.9087, samples=716  â†’ 0.9087 Ã— 716 = 650.6
Negative: F1=0.9508, samples=1192 â†’ 0.9508 Ã— 1192 = 1133.4
Neutral:  F1=0.4789, samples=106  â†’ 0.4789 Ã— 106 = 50.8

Weighted F1 = (650.6 + 1133.4 + 50.8) / 2014 = 0.9110
```

**Äáº·c Ä‘iá»ƒm:**
- âœ… Gáº§n vá»›i overall accuracy (91.10% â‰ˆ 91.06%)
- âœ… Pháº£n Ã¡nh performance trÃªn toÃ n dataset
- âŒ Che giáº¥u class yáº¿u (neutral chá»‰ 5% â†’ Ã­t áº£nh hÆ°á»Ÿng)

**Khi nÃ o dÃ¹ng:**
- âœ… Classes khÃ´ng quan trá»ng nhÆ° nhau (VD: spam nhiá»u hÆ¡n important email)
- âœ… Production: quan tÃ¢m overall performance
- âŒ KHÃ”NG dÃ¹ng khi muá»‘n cáº£i thiá»‡n class hiáº¿m

**Ã nghÄ©a:**
> "MÃ´ hÃ¬nh lÃ m tá»‘t **trÃªn toÃ n bá»™ dataset**"  
> Náº¿u Weighted cao nhÆ°ng Macro tháº¥p â†’ cÃ³ class hiáº¿m bá»‹ bá» rÆ¡i

---

### ğŸ” **So SÃ¡nh Macro vs Weighted**

| Metric | GiÃ¡ Trá»‹ | Ã NghÄ©a |
|--------|---------|---------|
| **Macro Avg** | 0.7795 | Model trung bÃ¬nh 78% trÃªn tá»«ng class (tháº¥p vÃ¬ neutral kÃ©o xuá»‘ng) |
| **Weighted Avg** | 0.9110 | Model Ä‘Ãºng 91% trÃªn toÃ n dataset (cao vÃ¬ neutral chiáº¿m Ã­t) |

**PhÃ¢n tÃ­ch model cá»§a báº¡n:**
```
Weighted (0.91) >> Macro (0.78)
â†’ Model tá»‘t trÃªn positive/negative (chiáº¿m 95% data)
â†’ NhÆ°ng Yáº¾U trÃªn neutral (chá»‰ 5% data)
â†’ Cáº§n cáº£i thiá»‡n neutral!
```

---

## ğŸ“‰ 3. LOSS FUNCTIONS (HÃ m Máº¥t MÃ¡t)

### ğŸ¯ **Loss LÃ  GÃ¬?**

**Äá»‹nh nghÄ©a:**  
Loss = Äá»™ "sai" cá»§a model trÃªn training data. Model há»c báº±ng cÃ¡ch **minimize loss**.

```
High Loss â†’ Model dá»± Ä‘oÃ¡n sai nhiá»u â†’ Há»c chÆ°a tá»‘t
Low Loss  â†’ Model dá»± Ä‘oÃ¡n gáº§n Ä‘Ãºng â†’ Há»c tá»‘t
```

---

### ğŸ“Š **1. Cross-Entropy Loss** (Loss CÆ¡ Báº£n)

**CÃ´ng thá»©c (cho 1 sample):**
```
Loss = -log(P_correct_class)

Náº¿u model tá»± tin Ä‘Ãºng â†’ P cao â†’ Loss tháº¥p
Náº¿u model khÃ´ng cháº¯c â†’ P tháº¥p â†’ Loss cao
```

**VÃ­ dá»¥:**
```python
Sample: "Pin tá»‘t" â†’ Label: Positive

TrÆ°á»ng há»£p 1: Model dá»± Ä‘oÃ¡n
  P(positive) = 0.9 â†’ Loss = -log(0.9) = 0.105 âœ… (tháº¥p)
  
TrÆ°á»ng há»£p 2: Model dá»± Ä‘oÃ¡n  
  P(positive) = 0.3 â†’ Loss = -log(0.3) = 1.204 âŒ (cao)
  
TrÆ°á»ng há»£p 3: Model hoÃ n toÃ n sai
  P(positive) = 0.01 â†’ Loss = -log(0.01) = 4.605 âŒâŒ (ráº¥t cao)
```

**Äáº·c Ä‘iá»ƒm:**
- âœ… Standard cho classification
- âŒ KhÃ´ng xá»­ lÃ½ class imbalance tá»‘t

---

### ğŸ”¥ **2. Focal Loss** (Xá»­ LÃ½ Imbalance)

**Model cá»§a báº¡n Ä‘ang dÃ¹ng Focal Loss!**

**CÃ´ng thá»©c:**
```
Focal Loss = -Î± Ã— (1 - P)^Î³ Ã— log(P)

Î± (alpha): class weight (neutral cao, positive/negative tháº¥p)
Î³ (gamma): focusing parameter (thÆ°á»ng = 2)
```

**CÃ¡ch hoáº¡t Ä‘á»™ng:**

```python
# Tá»« log cá»§a báº¡n:
Alpha weights:
  positive: 0.9360
  negative: 0.5644  
  neutral:  6.2515  â† Cao gáº¥p 11x!

Gamma = 2.0

VÃ­ dá»¥ 1: Easy sample (model tá»± tin Ä‘Ãºng)
  P = 0.95, class = neutral
  â†’ Focal Loss = 6.2515 Ã— (1-0.95)^2 Ã— log(0.95)
                = 6.2515 Ã— 0.0025 Ã— 0.051
                = 0.0008 âœ… (ráº¥t tháº¥p - bá» qua easy samples)

VÃ­ dá»¥ 2: Hard sample (model khÃ´ng cháº¯c)  
  P = 0.60, class = neutral
  â†’ Focal Loss = 6.2515 Ã— (1-0.60)^2 Ã— log(0.60)
                = 6.2515 Ã— 0.16 Ã— 0.51
                = 0.51 âŒ (cao - focus vÃ o hard samples)
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… **Alpha**: TÄƒng weight cho class hiáº¿m (neutral)
- âœ… **Gamma**: Focus vÃ o hard examples, bá» qua easy examples
- âœ… Xá»­ lÃ½ class imbalance tá»‘t

**Táº¡i sao cáº§n:**
```
Neutral chá»‰ 5% data (501/9396)
â†’ Cross-Entropy Loss: Model há»c positive/negative nhiá»u hÆ¡n
â†’ Focal Loss: Buá»™c model chÃº Ã½ Ä‘áº¿n neutral (alpha=6.25)
```

---

### ğŸ“ˆ **3. Eval Loss vs Training Loss**

**Training Loss:**
- Äá»™ sai cá»§a model trÃªn **training data**
- Giáº£m dáº§n qua cÃ¡c epochs

**Eval Loss:**
- Äá»™ sai cá»§a model trÃªn **validation data** (data model chÆ°a tháº¥y)
- ÄÃ¡nh giÃ¡ kháº£ nÄƒng generalize

**Tá»« log cá»§a báº¡n:**
```
Epoch 1: train_loss=?, eval_loss=0.233  
Epoch 2: train_loss=?, eval_loss=0.207 â† BEST (tháº¥p nháº¥t)
Epoch 3: train_loss=?, eval_loss=0.214 â†‘ (tÄƒng nháº¹)
Epoch 4: train_loss=?, eval_loss=0.356 â†‘â†‘ (tÄƒng 70%!)

â†’ OVERFITTING! Model há»c thuá»™c training, khÃ´ng generalize
```

**Giáº£i thÃ­ch:**
```
Epoch 1-2: 
  Train loss â†“, Eval loss â†“
  â†’ Model Ä‘ang há»c tá»‘t âœ…

Epoch 3-4:
  Train loss â†“â†“, Eval loss â†‘â†‘  
  â†’ Model há»c thuá»™c training data (overfitting) âŒ
  â†’ Cáº§n dá»«ng láº¡i á»Ÿ epoch 2!
```

---

## ğŸ“Š 4. KHI NÃ€O DÃ™NG METRIC NÃ€O?

### ğŸ¯ **Use Case: Sentiment Analysis (Model Cá»§a Báº¡n)**

| Má»¥c tiÃªu | Metric | Táº¡i sao |
|----------|--------|---------|
| **Overall performance** | Accuracy, Weighted F1 | ÄÃ¡nh giÃ¡ tá»•ng quan |
| **Má»—i class quan trá»ng nhÆ° nhau** | Macro F1 | PhÃ¡t hiá»‡n class yáº¿u (neutral) |
| **Cáº£i thiá»‡n class neutral** | F1-neutral, Recall-neutral | Focus vÃ o class cá»¥ thá»ƒ |
| **Detect overfitting** | Eval Loss | Theo dÃµi loss tÄƒng |

**Khuyáº¿n nghá»‹ cho báº¡n:**
```
Æ¯u tiÃªn 1: Macro F1 (phÃ¡t hiá»‡n neutral yáº¿u)
Æ¯u tiÃªn 2: F1 per class (neutral, positive, negative)
Æ¯u tiÃªn 3: Eval Loss (trÃ¡nh overfitting)
```

---

### ğŸ¥ **Use Case: Medical Diagnosis**

```
Bá»‡nh: Ung thÆ° (hiáº¿m, 2%), KhÃ´ng ung thÆ° (98%)

Metric quan trá»ng: RECALL trÃªn class ung thÆ°
â†’ KHÃ”NG Ä‘Æ°á»£c bá» sÃ³t bá»‡nh nhÃ¢n ung thÆ° (FN = 0)
â†’ CÃ³ thá»ƒ cháº¥p nháº­n bÃ¡o Ä‘á»™ng nháº§m (FP cao á»•n)

Tá»‡ nháº¥t: Recall-cancer = 70% 
â†’ Bá» sÃ³t 30% bá»‡nh nhÃ¢n â†’ CHáº¾T!
```

---

### ğŸ” **Use Case: Search Engine**

```
Query: "python tutorials"

Metric quan trá»ng: PRECISION@10 (top 10 results)
â†’ 10 káº¿t quáº£ Ä‘áº§u PHáº¢I chÃ­nh xÃ¡c
â†’ CÃ³ thá»ƒ bá» sÃ³t má»™t sá»‘ káº¿t quáº£ (Recall tháº¥p á»•n)

Tá»‡ nháº¥t: Precision = 20%
â†’ 8/10 káº¿t quáº£ khÃ´ng liÃªn quan â†’ User rá»i Ä‘i
```

---

### ğŸš¨ **Use Case: Spam Filter**

```
2 loáº¡i lá»—i:
1. False Positive: Email quan trá»ng â†’ Spam folder âŒâŒ
2. False Negative: Spam â†’ Inbox âŒ

Metric quan trá»ng: PRECISION trÃªn class spam
â†’ Chá»‰ Ä‘Ã¡nh dáº¥u spam khi cháº¯c cháº¯n
â†’ CÃ³ thá»ƒ Ä‘á»ƒ má»™t Ã­t spam lá»t (FN) vÃ o inbox
```

---

## ğŸ¯ 5. ÃP Dá»¤NG VÃ€O MODEL Cá»¦A Báº N

### ğŸ“Š **PhÃ¢n TÃ­ch Káº¿t Quáº£ Hiá»‡n Táº¡i**

```
              precision  recall  f1-score  support

    positive     0.8934   0.9246    0.9087      716
    negative     0.9614   0.9404    0.9508     1192
     neutral     0.4766   0.4811    0.4789      106  â† Váº¤N Äá»€

    accuracy                         0.9106     2014
   macro avg     0.7771   0.7820    0.7795     2014  â† Tháº¥p vÃ¬ neutral
weighted avg     0.9117   0.9106    0.9110     2014  â† Cao vÃ¬ neutral Ã­t
```

### ğŸ” **Giáº£i ThÃ­ch Chi Tiáº¿t**

**1. Positive Class:**
```
Precision = 0.89 â†’ Khi model nÃ³i "positive", Ä‘Ãºng 89%
Recall = 0.92    â†’ TÃ¬m Ä‘Æ°á»£c 92% cÃ¢u positive thá»±c táº¿
F1 = 0.91        â†’ CÃ¢n báº±ng tá»‘t âœ…

Ã nghÄ©a: Model lÃ m Tá»T trÃªn positive
```

**2. Negative Class:**
```
Precision = 0.96 â†’ Khi model nÃ³i "negative", Ä‘Ãºng 96%
Recall = 0.94    â†’ TÃ¬m Ä‘Æ°á»£c 94% cÃ¢u negative thá»±c táº¿  
F1 = 0.95        â†’ Ráº¥t tá»‘t âœ…

Ã nghÄ©a: Model lÃ m XUáº¤T Sáº®C trÃªn negative (class lá»›n nháº¥t)
```

**3. Neutral Class:**
```
Precision = 0.48 â†’ Khi model nÃ³i "neutral", CHá»ˆ Ä‘Ãºng 48% âŒ
Recall = 0.48    â†’ Chá»‰ tÃ¬m Ä‘Æ°á»£c 48% cÃ¢u neutral thá»±c táº¿ âŒ
F1 = 0.48        â†’ Ráº¤T THáº¤P âŒ

Ã nghÄ©a: Model gáº§n nhÆ° ÄOÃN MÃ’ trÃªn neutral (50-50)
NguyÃªn nhÃ¢n: Neutral chá»‰ 106 samples (5.3%) â†’ quÃ¡ Ã­t!
```

**4. Overall Metrics:**
```
Accuracy = 91.06%
â†’ NhÃ¬n cÃ³ váº» tá»‘t, nhÆ°ng...

Macro F1 = 0.78 (tháº¥p)
â†’ PhÃ¡t hiá»‡n ra neutral Ráº¤T Yáº¾U

Weighted F1 = 0.91 (cao)
â†’ Che giáº¥u neutral (vÃ¬ neutral chiáº¿m Ã­t)

Káº¾T LUáº¬N:
â†’ Model tá»‘t trÃªn positive/negative (95% data)
â†’ Model Yáº¾U trÃªn neutral (5% data)
â†’ Cáº¦N cáº£i thiá»‡n neutral!
```

---

### ğŸ¯ **Má»¥c TiÃªu Cáº£i Thiá»‡n**

| Metric | Hiá»‡n táº¡i | Má»¥c tiÃªu | CÃ¡ch Ä‘áº¡t |
|--------|----------|----------|----------|
| **Neutral F1** | 0.48 | **0.65-0.70** | Oversampling 30% |
| **Macro F1** | 0.78 | **0.83-0.85** | Cáº£i thiá»‡n neutral |
| **Weighted F1** | 0.91 | **0.92** | Tá»± Ä‘á»™ng tÄƒng khi neutral tá»‘t |
| **Eval Loss** | TÄƒng á»Ÿ epoch 4 | **KhÃ´ng tÄƒng** | Giáº£m epochs: 5â†’3 |

---

## ğŸ“š TÃ“M Táº®T

### ğŸ¯ **Metrics - Khi NÃ o DÃ¹ng**

| Metric | Má»¥c ÄÃ­ch | Khi NÃ o DÃ¹ng |
|--------|----------|--------------|
| **Accuracy** | Tá»· lá»‡ Ä‘Ãºng tá»•ng thá»ƒ | Classes cÃ¢n báº±ng |
| **Precision** | "Náº¿u model nÃ³i Positive, tin Ä‘Æ°á»£c khÃ´ng?" | KhÃ´ng muá»‘n False Positive (spam, legal) |
| **Recall** | "Model cÃ³ bá» sÃ³t khÃ´ng?" | KhÃ´ng muá»‘n False Negative (medical, security) |
| **F1 Score** | CÃ¢n báº±ng Precision & Recall | Classes imbalance, so sÃ¡nh models |
| **Macro Avg** | Trung bÃ¬nh trÃªn má»—i class | Má»—i class quan trá»ng nhÆ° nhau, phÃ¡t hiá»‡n class yáº¿u |
| **Weighted Avg** | Weighted theo sá»‘ samples | Quan tÃ¢m overall performance |
| **Loss** | Äá»™ sai cá»§a model | Detect overfitting, theo dÃµi training |

---

### ğŸ”¥ **Loss Functions**

| Loss | Äáº·c Äiá»ƒm | Khi DÃ¹ng |
|------|----------|----------|
| **Cross-Entropy** | Standard loss | Classes cÃ¢n báº±ng |
| **Focal Loss** | Alpha (class weight) + Gamma (focus hard) | Classes imbalance âœ… (Model cá»§a báº¡n) |

---

### âš¡ **Quick Reference**

```python
# Confusion Matrix
TP = True Positive   (dá»± Ä‘oÃ¡n Ä‘Ãºng positive)
TN = True Negative   (dá»± Ä‘oÃ¡n Ä‘Ãºng negative)
FP = False Positive  (dá»± Ä‘oÃ¡n sai thÃ nh positive)
FN = False Negative  (dá»± Ä‘oÃ¡n sai thÃ nh negative)

# Metrics
Accuracy  = (TP + TN) / (TP + TN + FP + FN)
Precision = TP / (TP + FP)              # Dá»± Ä‘oÃ¡n positive cÃ³ chÃ­nh xÃ¡c khÃ´ng?
Recall    = TP / (TP + FN)              # TÃ¬m Ä‘Æ°á»£c bao nhiÃªu % positive thá»±c táº¿?
F1        = 2 Ã— Precision Ã— Recall / (Precision + Recall)

# Average
Macro Avg    = Trung bÃ¬nh Ä‘Æ¡n giáº£n trÃªn má»—i class
Weighted Avg = Trung bÃ¬nh cÃ³ trá»ng sá»‘ theo sá»‘ samples
```

---

## ğŸ“ TÃ€I LIá»†U THAM KHáº¢O

### ğŸ“– **Äá»c ThÃªm**
- [Precision vs Recall](https://en.wikipedia.org/wiki/Precision_and_recall)
- [F1 Score Explained](https://en.wikipedia.org/wiki/F-score)
- [Focal Loss Paper](https://arxiv.org/abs/1708.02002)
- [Imbalanced Learning](https://imbalanced-learn.org/)

### ğŸ¯ **Tip Cuá»‘i**

> **"KhÃ´ng cÃ³ metric nÃ o lÃ  hoÃ n háº£o"**
> 
> - Accuracy cao khÃ´ng cÃ³ nghÄ©a model tá»‘t (náº¿u imbalance)
> - F1 cao trÃªn class nÃ y, tháº¥p trÃªn class kia
> - LuÃ´n nhÃ¬n NHIá»€U metrics cÃ¹ng lÃºc
> - Hiá»ƒu business context Ä‘á»ƒ chá»n metric phÃ¹ há»£p
> 
> **Model cá»§a báº¡n:**
> - Accuracy = 91% (tá»‘t)  
> - NhÆ°ng Neutral F1 = 48% (tá»‡)
> - â†’ Cáº§n cáº£i thiá»‡n neutral!

---

Hy vá»ng giÃºp báº¡n hiá»ƒu rÃµ hÆ¡n vá» cÃ¡c metrics! ğŸš€
