"""
Script Test Sentiment SMART v·ªõi Aspect Relevance Detection
==========================================================
Ch·ªâ hi·ªÉn th·ªã c√°c aspect TH·ª∞C S·ª∞ ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p trong c√¢u
S·ª≠ d·ª•ng keyword matching + confidence filtering

Usage:
    # Interactive mode
    python test_sentiment_smart.py
    
    # Test single sentence
    python test_sentiment_smart.py --sentence "pin t·ªá qu√°"
    python test_sentiment_smart.py --sentence "pin t·ªá qu√°" --show-ignored
    
    # Batch mode
    python test_sentiment_smart.py --batch test_examples.txt
    
    # Evaluation mode - T√≠nh accuracy tr√™n t·∫≠p test/validation
    python test_sentiment_smart.py --evaluate data/test.csv
    python test_sentiment_smart.py --evaluate data/validation.csv
"""

import sys
import io
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

import os
import argparse
import torch
import numpy as np
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import re
from colorama import init, Fore, Style
import pandas as pd
from collections import defaultdict
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix

init(autoreset=True)

# Configuration
MODEL_PATH = "finetuned_visobert_absa_model"
MAX_LENGTH = 256

# Aspect keywords (t·ª´ kh√≥a ti·∫øng Vi·ªát cho m·ªói aspect)
ASPECT_KEYWORDS = {
    'Battery': [
        'pin', 's·∫°c', 'x·∫°c', 'dung l∆∞·ª£ng pin', 'mah', 'battery', 'tr√¢u pin',
        'h·∫øt pin', 't·ª•t pin', 'chai pin', 'ph√¨nh pin', 't·ªën pin', 'ng·ªën pin'
    ],
    'Camera': [
        'camera', 'cam', 'ch·ª•p', 'quay', '·∫£nh', 'h√¨nh', 'selfie', 'tele',
        'zoom', 'g√≥c r·ªông', 'ch√¢n dung', 'macro', '·ªëng k√≠nh', 'megapixel', 'mp'
    ],
    'Performance': [
        'hi·ªáu nƒÉng', 'm∆∞·ª£t', 'lag', 'gi·∫≠t', 'ƒë∆°', 'nhanh', 'ch·∫≠m', 'm·∫°nh',
        'y·∫øu', 'chip', 'cpu', 'gpu', 'ram', 'snapdragon', 'mediatek', 'dimensity',
        'x·ª≠ l√Ω', 'ƒëa nhi·ªám', 'gaming', 'game', 'fps'
    ],
    'Display': [
        'm√†n h√¨nh', 'm√†n', 'screen', 'display', 'hi·ªÉn th·ªã', 'ƒë·ªô ph√¢n gi·∫£i',
        'amoled', 'lcd', 'oled', 'ips', 't·∫•m n·ªÅn', 'hz', 'refresh rate',
        's√°ng', 't·ªëi', 'n·∫Øng', 'xem phim', 's·∫Øc n√©t', 'm·ªù', 'tr·∫ßy m√†n'
    ],
    'Design': [
        'thi·∫øt k·∫ø', 'ƒë·∫πp', 'x·∫•u', 'sang', 'b√≥ng', 'nh√°m', 'vu√¥ng', 'tr√≤n',
        'kim lo·∫°i', 'nh·ª±a', 'k√≠nh', 'v·ªè', 'khung', 'c·∫ßm', 'n·∫Øm', 'ergonomic',
        'm√†u', 'color', 'style', 'ki·ªÉu d√°ng', 'ngo·∫°i h√¨nh', 'b·ªÅ ngo√†i'
    ],
    'Software': [
        'ph·∫ßn m·ªÅm', 'software', 'h·ªá ƒëi·ªÅu h√†nh', 'os', 'android', 'ios',
        'miui', 'one ui', 'coloros', 'funtouch', 'realme ui', 'oxygen',
        'update', 'c·∫≠p nh·∫≠t', 'app', '·ª©ng d·ª•ng', 'bloatware', 'qu·∫£ng c√°o'
    ],
    'Packaging': [
        'ƒë√≥ng g√≥i', 'h·ªôp', 'box', 'bao b√¨', 'packaging', 'g√≥i', 'ni√™m phong',
        'seal', 'tem', 'fullbox', 'nguy√™n seal'
    ],
    'Price': [
        'gi√°', 'price', 'ti·ªÅn', 'r·∫ª', 'ƒë·∫Øt', 'm·∫Øc', 'ph·∫£i chƒÉng', 'h·ª£p l√Ω',
        'cost', 'budget', 't√∫i ti·ªÅn', 'kho·∫£n', 'vnƒë', 'tri·ªáu', 'ngh√¨n',
        'gi√° tr·ªã', 'value', 'ƒë√°ng gi√°'
    ],
    'Audio': [
        '√¢m thanh', 'audio', 'loa', 'speaker', 'ti·∫øng', 'nghe', 'nghe nh·∫°c',
        '√¢m', 'bass', 'treble', 'stereo', 'mono', 'volume', '√¢m l∆∞·ª£ng',
        'to', 'nh·ªè', 'r√®', 'r√≠t', 'dolby', 'hifi', 'ch·∫•t l∆∞·ª£ng √¢m thanh'
    ],
    'Warranty': [
        'b·∫£o h√†nh', 'warranty', 'bh', 'ƒë·ªïi tr·∫£', 'guarantee', 'h·ªó tr·ª£',
        'claim', 's·ª≠a ch·ªØa', 'service center', 'trung t√¢m b·∫£o h√†nh'
    ],
    'Shop_Service': [
        'shop', 'c·ª≠a h√†ng', 'store', 'seller', 'ng∆∞·ªùi b√°n', 'ch·ªß shop',
        't∆∞ v·∫•n', 'h·ªó tr·ª£', 'nhi·ªát t√¨nh', 'th√°i ƒë·ªô', 'ph·ª•c v·ª•', 'service',
        'chƒÉm s√≥c', 'tr·∫£ l·ªùi', 'chat'
    ],
    'Shipping': [
        'giao h√†ng', 'ship', 'v·∫≠n chuy·ªÉn', 'delivery', 'shipper', 'giao',
        'nh·∫≠n h√†ng', 'ship nhanh', 'ship ch·∫≠m', 'giao nhanh', 'giao ch·∫≠m',
        'shipper', 'ƒë√≥ng g√≥i giao h√†ng'
    ],
    'General': [
        'm√°y', 'ƒëi·ªán tho·∫°i', 'phone', 'smartphone', 'device', 's·∫£n ph·∫©m',
        'product', 'h√†ng', 'overall', 't·ªïng th·ªÉ', 'chung', 'n√≥i chung',
        't·ªët', 'x·∫•u', 'ok', 'oke', '·ªïn', 'ƒë∆∞·ª£c'
    ],
    'Others': [
        'kh√°c', 'other', 'ph·ª• ki·ªán', 'accessory', 'tai nghe', 's·∫°c d·ª± ph√≤ng'
    ]
}

ID2LABEL = {0: 'positive', 1: 'negative', 2: 'neutral'}
LABEL2ID = {'positive': 0, 'negative': 1, 'neutral': 2}


def check_aspect_relevance(sentence, aspect):
    """
    Ki·ªÉm tra xem aspect c√≥ ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p trong c√¢u kh√¥ng
    
    Returns:
        float: relevance score (0.0 - 1.0)
    """
    sentence_lower = sentence.lower()
    keywords = ASPECT_KEYWORDS.get(aspect, [])
    
    if not keywords:
        return 0.0
    
    # ƒê·∫øm s·ªë keywords xu·∫•t hi·ªán
    matches = 0
    for keyword in keywords:
        if keyword.lower() in sentence_lower:
            matches += 1
    
    # Relevance score = s·ªë keywords match / t·ªïng s·ªë keywords
    # Bonus n·∫øu c√≥ √≠t nh·∫•t 1 match
    if matches > 0:
        base_score = matches / len(keywords)
        # Boost score n·∫øu c√≥ match (√≠t nh·∫•t 0.3)
        relevance_score = max(0.3, min(1.0, base_score * 5))
        return relevance_score
    
    return 0.0


class SmartSentimentPredictor:
    """Predictor th√¥ng minh v·ªõi aspect relevance detection"""
    
    def __init__(self, model_path=MODEL_PATH):
        """Kh·ªüi t·∫°o predictor"""
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"üîß ƒêang load m√¥ h√¨nh t·ª´: {model_path}")
        print(f"üîß Device: {self.device}")
        
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(model_path)
            self.model = AutoModelForSequenceClassification.from_pretrained(model_path)
            self.model.to(self.device)
            self.model.eval()
            print(f"‚úì Load m√¥ h√¨nh th√†nh c√¥ng!\n")
        except Exception as e:
            print(f"‚ùå L·ªói khi load m√¥ h√¨nh: {str(e)}")
            sys.exit(1)
    
    def predict_single(self, sentence, aspect):
        """D·ª± ƒëo√°n sentiment cho m·ªôt aspect"""
        # X·ª≠ l√Ω VNCoreNLP segmentation n·∫øu c√≥
        sentence = sentence.replace('_', ' ')
        
        inputs = self.tokenizer(
            sentence, aspect,
            return_tensors='pt',
            max_length=MAX_LENGTH,
            truncation=True,
            padding=True
        )
        
        inputs = {k: v.to(self.device) for k, v in inputs.items()}
        
        with torch.no_grad():
            outputs = self.model(**inputs)
            logits = outputs.logits
            probs = torch.softmax(logits, dim=-1).cpu().numpy()[0]
        
        predicted_idx = np.argmax(probs)
        predicted_sentiment = ID2LABEL[predicted_idx]
        confidence = probs[predicted_idx]
        
        probabilities = {
            ID2LABEL[i]: float(probs[i]) for i in range(len(probs))
        }
        
        return {
            'aspect': aspect,
            'sentiment': predicted_sentiment,
            'confidence': float(confidence),
            'probabilities': probabilities
        }
    
    def predict_smart(self, sentence, confidence_threshold=0.7, relevance_threshold=0.3):
        """
        D·ª± ƒëo√°n TH√îNG MINH - ch·ªâ aspects ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p
        
        Args:
            sentence: C√¢u c·∫ßn ph√¢n t√≠ch
            confidence_threshold: Ng∆∞·ª°ng confidence t·ªëi thi·ªÉu
            relevance_threshold: Ng∆∞·ª°ng relevance t·ªëi thi·ªÉu (aspect ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p)
            
        Returns:
            dict: {
                'relevant_aspects': list (aspects ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p v·ªõi sentiment),
                'all_results': list (t·∫•t c·∫£ aspects),
                'ignored_aspects': list (aspects b·ªã ignore v√¨ kh√¥ng relevance)
            }
        """
        all_results = []
        relevant_aspects = []
        ignored_aspects = []
        
        print(f"\n{Fore.CYAN}üîç ƒêang ph√¢n t√≠ch aspect relevance...{Style.RESET_ALL}")
        
        for aspect in ASPECT_KEYWORDS.keys():
            # Check relevance
            relevance_score = check_aspect_relevance(sentence, aspect)
            
            # Predict sentiment
            result = self.predict_single(sentence, aspect)
            result['relevance_score'] = relevance_score
            
            all_results.append(result)
            
            # Ch·ªâ th√™m v√†o relevant n·∫øu:
            # 1. C√≥ relevance score > threshold
            # 2. Confidence > threshold
            # 3. Kh√¥ng ph·∫£i neutral (ho·∫∑c neutral v·ªõi confidence th·∫•p)
            if relevance_score >= relevance_threshold:
                if result['confidence'] >= confidence_threshold:
                    relevant_aspects.append(result)
                elif result['sentiment'] != 'neutral':
                    # Aspect ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p nh∆∞ng confidence th·∫•p - v·∫´n th√™m v√†o
                    relevant_aspects.append(result)
            else:
                ignored_aspects.append({
                    'aspect': aspect,
                    'reason': f'Not mentioned (relevance: {relevance_score:.2f})'
                })
        
        # Sort by relevance score
        relevant_aspects = sorted(relevant_aspects, 
                                 key=lambda x: (x['relevance_score'], x['confidence']), 
                                 reverse=True)
        
        return {
            'relevant_aspects': relevant_aspects,
            'all_results': all_results,
            'ignored_aspects': ignored_aspects
        }


def format_sentiment_emoji(sentiment):
    """Emoji cho sentiment"""
    return {'positive': 'üòä', 'negative': 'üòû', 'neutral': 'üòê'}.get(sentiment, '')


def format_confidence_bar(confidence, width=20):
    """Progress bar"""
    filled = int(confidence * width)
    return '‚ñà' * filled + '‚ñë' * (width - filled)


def print_smart_results(sentence, results, show_ignored=False):
    """In k·∫øt qu·∫£ th√¥ng minh"""
    print(f"\n{'='*80}")
    print(f"üìù C√¢u ph√¢n t√≠ch: {Fore.CYAN}{sentence}{Style.RESET_ALL}")
    print(f"{'='*80}\n")
    
    relevant = results['relevant_aspects']
    ignored = results['ignored_aspects']
    
    if relevant:
        print(f"{Fore.GREEN}üéØ C√ÅC ASPECT ƒê∆Ø·ª¢C ƒê·ªÄ C·∫¨P:{Style.RESET_ALL}\n")
        
        for idx, result in enumerate(relevant, 1):
            aspect = result['aspect']
            sentiment = result['sentiment']
            confidence = result['confidence']
            relevance = result['relevance_score']
            emoji = format_sentiment_emoji(sentiment)
            
            # M√†u theo sentiment
            color = {
                'positive': Fore.GREEN,
                'negative': Fore.RED,
                'neutral': Fore.YELLOW
            }.get(sentiment, '')
            
            print(f"{idx}. {Fore.CYAN}{aspect:<15}{Style.RESET_ALL} ‚Üí "
                  f"{emoji} {color}{sentiment.upper():<10}{Style.RESET_ALL}")
            print(f"   Confidence: {confidence*100:.1f}% | Relevance: {relevance*100:.1f}%")
            
            # Progress bars
            conf_bar = format_confidence_bar(confidence)
            rel_bar = format_confidence_bar(relevance)
            print(f"   Conf: {conf_bar} {confidence*100:.1f}%")
            print(f"   Rel:  {rel_bar} {relevance*100:.1f}%\n")
    else:
        print(f"{Fore.YELLOW}‚ö†Ô∏è  Kh√¥ng ph√°t hi·ªán aspect c·ª• th·ªÉ n√†o ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p{Style.RESET_ALL}\n")
    
    # Hi·ªÉn th·ªã aspects b·ªã ignore
    if show_ignored and ignored:
        print(f"\n{Fore.BLUE}üö´ ASPECTS B·ªä B·ªé QUA (kh√¥ng ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p):{Style.RESET_ALL}")
        for item in ignored[:5]:  # Ch·ªâ hi·ªÉn th·ªã 5 c√°i ƒë·∫ßu
            print(f"   ‚Ä¢ {item['aspect']}: {item['reason']}")
        if len(ignored) > 5:
            print(f"   ... v√† {len(ignored) - 5} aspects kh√°c")


def print_compact_results(sentence, results):
    """In k·∫øt qu·∫£ d·∫°ng compact cho batch mode"""
    relevant = results['relevant_aspects']
    
    print(f"\nüìù \"{sentence}\"")
    
    if relevant:
        print(f"‚Üí Ph√°t hi·ªán {len(relevant)} aspect(s) ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p:")
        for r in relevant:
            emoji = format_sentiment_emoji(r['sentiment'])
            print(f"   ‚Ä¢ {r['aspect']}: {emoji} {r['sentiment']} "
                  f"(conf: {r['confidence']*100:.1f}%, rel: {r['relevance_score']*100:.1f}%)")
    else:
        print(f"‚Üí Kh√¥ng ph√°t hi·ªán aspect c·ª• th·ªÉ n√†o")
    print()


def batch_mode(predictor, sentences):
    """Ch·∫ø ƒë·ªô batch - test nhi·ªÅu c√¢u t·ª´ file"""
    print(f"\n{'='*80}")
    print(f"{Fore.GREEN}üì¶ CH·∫æ ƒê·ªò BATCH - Test {len(sentences)} c√¢u{Style.RESET_ALL}")
    print(f"{'='*80}\n")
    
    for idx, sentence in enumerate(sentences, 1):
        print(f"{Fore.BLUE}[{idx}/{len(sentences)}]{Style.RESET_ALL}", end=" ")
        
        # Predict
        results = predictor.predict_smart(sentence)
        
        # Print compact
        print_compact_results(sentence, results)


def evaluate_model(predictor, data_path):
    """
    ƒê√°nh gi√° model tr√™n t·∫≠p test/validation
    T√≠nh accuracy, precision, recall, F1 cho t·ª´ng aspect
    """
    print(f"\n{Fore.CYAN}üìä ƒê√ÅNH GI√Å MODEL{Style.RESET_ALL}")
    print(f"{'='*80}\n")
    print(f"ƒêang load d·ªØ li·ªáu t·ª´: {data_path}")
    
    # Load data
    df = pd.read_csv(data_path, encoding='utf-8')
    print(f"‚úì ƒê√£ load {len(df)} samples\n")
    
    # Group by aspect
    aspect_metrics = defaultdict(lambda: {
        'y_true': [],
        'y_pred': [],
        'confidences': [],
        'relevances': [],
        'total': 0
    })
    
    print(f"{Fore.CYAN}‚è≥ ƒêang d·ª± ƒëo√°n...{Style.RESET_ALL}\n")
    
    # Predict for each sample
    for idx, row in df.iterrows():
        sentence = row['sentence']
        aspect = row['aspect']
        true_sentiment = row['sentiment']
        
        # Predict without printing
        result = predictor.predict_single(sentence, aspect)
        relevance_score = check_aspect_relevance(sentence, aspect)
        
        # Store results
        aspect_metrics[aspect]['y_true'].append(true_sentiment)
        aspect_metrics[aspect]['y_pred'].append(result['sentiment'])
        aspect_metrics[aspect]['confidences'].append(result['confidence'])
        aspect_metrics[aspect]['relevances'].append(relevance_score)
        aspect_metrics[aspect]['total'] += 1
        
        # Progress
        if (idx + 1) % 100 == 0:
            print(f"  ƒê√£ x·ª≠ l√Ω: {idx + 1}/{len(df)} samples ({(idx+1)/len(df)*100:.1f}%)")
    
    print(f"\n‚úì Ho√†n th√†nh d·ª± ƒëo√°n!\n")
    
    # Calculate metrics for each aspect
    print(f"\n{Fore.GREEN}{'='*80}{Style.RESET_ALL}")
    print(f"{Fore.GREEN}üìà K·∫æT QU·∫¢ CHI TI·∫æT THEO ASPECT{Style.RESET_ALL}")
    print(f"{Fore.GREEN}{'='*80}{Style.RESET_ALL}\n")
    
    overall_true = []
    overall_pred = []
    
    results_list = []
    
    for aspect in sorted(aspect_metrics.keys()):
        metrics = aspect_metrics[aspect]
        y_true = metrics['y_true']
        y_pred = metrics['y_pred']
        
        overall_true.extend(y_true)
        overall_pred.extend(y_pred)
        
        # Calculate metrics
        accuracy = accuracy_score(y_true, y_pred)
        precision, recall, f1, _ = precision_recall_fscore_support(
            y_true, y_pred, average='weighted', zero_division=0
        )
        
        avg_conf = np.mean(metrics['confidences'])
        avg_rel = np.mean(metrics['relevances'])
        
        results_list.append({
            'aspect': aspect,
            'total': metrics['total'],
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'avg_conf': avg_conf,
            'avg_rel': avg_rel
        })
        
        # Print detailed results
        print(f"{Fore.CYAN}{'‚îÄ'*80}{Style.RESET_ALL}")
        print(f"{Fore.CYAN}Aspect: {aspect}{Style.RESET_ALL}")
        print(f"{'‚îÄ'*80}")
        print(f"  Total samples:        {metrics['total']}")
        print(f"  Accuracy:            {accuracy:.2%} {format_confidence_bar(accuracy, 30)}")
        print(f"  Precision:           {precision:.2%} {format_confidence_bar(precision, 30)}")
        print(f"  Recall:              {recall:.2%} {format_confidence_bar(recall, 30)}")
        print(f"  F1-Score:            {f1:.2%} {format_confidence_bar(f1, 30)}")
        print(f"  Avg Confidence:      {avg_conf:.2%} {format_confidence_bar(avg_conf, 30)}")
        print(f"  Avg Relevance:       {avg_rel:.2%} {format_confidence_bar(avg_rel, 30)}")
        print()
    
    # Overall metrics
    print(f"\n{Fore.GREEN}{'='*80}{Style.RESET_ALL}")
    print(f"{Fore.GREEN}üìä K·∫æT QU·∫¢ T·ªîNG QU√ÅT (ALL ASPECTS){Style.RESET_ALL}")
    print(f"{Fore.GREEN}{'='*80}{Style.RESET_ALL}\n")
    
    overall_accuracy = accuracy_score(overall_true, overall_pred)
    overall_precision, overall_recall, overall_f1, _ = precision_recall_fscore_support(
        overall_true, overall_pred, average='weighted', zero_division=0
    )
    
    print(f"  Total samples:        {len(overall_true)}")
    print(f"  Overall Accuracy:     {overall_accuracy:.2%} {format_confidence_bar(overall_accuracy, 30)}")
    print(f"  Overall Precision:    {overall_precision:.2%} {format_confidence_bar(overall_precision, 30)}")
    print(f"  Overall Recall:       {overall_recall:.2%} {format_confidence_bar(overall_recall, 30)}")
    print(f"  Overall F1-Score:     {overall_f1:.2%} {format_confidence_bar(overall_f1, 30)}")
    
    # Summary table
    print(f"\n{Fore.YELLOW}üìã B·∫¢NG T·ªîNG H·ª¢P METRICS{Style.RESET_ALL}")
    print(f"{'='*110}")
    print(f"{'Aspect':<15} {'Samples':>8} {'Accuracy':>10} {'Precision':>10} {'Recall':>10} {'F1':>10} {'AvgConf':>10} {'AvgRel':>10}")
    print(f"{'='*110}")
    
    for r in results_list:
        print(f"{r['aspect']:<15} {r['total']:>8} "
              f"{r['accuracy']:>9.1%} {r['precision']:>9.1%} "
              f"{r['recall']:>9.1%} {r['f1']:>9.1%} "
              f"{r['avg_conf']:>9.1%} {r['avg_rel']:>9.1%}")
    
    print(f"{'='*110}")
    print(f"{'OVERALL':<15} {len(overall_true):>8} "
          f"{overall_accuracy:>9.1%} {overall_precision:>9.1%} "
          f"{overall_recall:>9.1%} {overall_f1:>9.1%} "
          f"{'‚îÄ':>10} {'‚îÄ':>10}")
    print(f"{'='*110}\n")
    
    return {
        'aspect_metrics': results_list,
        'overall': {
            'accuracy': overall_accuracy,
            'precision': overall_precision,
            'recall': overall_recall,
            'f1': overall_f1
        }
    }


def interactive_mode(predictor):
    """Ch·∫ø ƒë·ªô t∆∞∆°ng t√°c"""
    print(f"\n{'='*80}")
    print(f"{Fore.GREEN}üîÆ CH·∫æ ƒê·ªò T∆Ø∆†NG T√ÅC TH√îNG MINH - SMART ABSA{Style.RESET_ALL}")
    print(f"{'='*80}")
    print(f"\nT√≠nh nƒÉng:")
    print(f"  ‚Ä¢ T·ª± ƒë·ªông ph√°t hi·ªán aspects ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p trong c√¢u")
    print(f"  ‚Ä¢ L·ªçc b·ªè aspects kh√¥ng li√™n quan")
    print(f"  ‚Ä¢ Hi·ªÉn th·ªã relevance score cho m·ªói aspect")
    print(f"\nH∆∞·ªõng d·∫´n:")
    print(f"  ‚Ä¢ Nh·∫≠p c√¢u ƒë·ªÉ ph√¢n t√≠ch")
    print(f"  ‚Ä¢ G√µ 'ignored' sau c√¢u ƒë·ªÉ xem aspects b·ªã b·ªè qua")
    print(f"  ‚Ä¢ G√µ 'quit' ƒë·ªÉ tho√°t")
    print(f"\n{'-'*80}\n")
    
    while True:
        try:
            user_input = input(f"{Fore.YELLOW}Nh·∫≠p c√¢u:{Style.RESET_ALL} ").strip()
            
            if not user_input:
                continue
            
            if user_input.lower() in ['quit', 'exit', 'q']:
                print(f"\n{Fore.CYAN}üëã T·∫°m bi·ªát!{Style.RESET_ALL}\n")
                break
            
            # Check show ignored
            show_ignored = False
            if user_input.lower().endswith(' ignored'):
                show_ignored = True
                user_input = user_input[:-8].strip()
            
            # Predict
            print(f"\n{Fore.CYAN}‚è≥ ƒêang ph√¢n t√≠ch...{Style.RESET_ALL}")
            results = predictor.predict_smart(user_input)
            
            # Print results
            print_smart_results(user_input, results, show_ignored=show_ignored)
            
            print(f"\n{'-'*80}\n")
            
        except KeyboardInterrupt:
            print(f"\n\n{Fore.CYAN}üëã T·∫°m bi·ªát!{Style.RESET_ALL}\n")
            break
        except Exception as e:
            print(f"\n{Fore.RED}‚ùå L·ªói: {str(e)}{Style.RESET_ALL}\n")


def main():
    """Main function"""
    parser = argparse.ArgumentParser(
        description='Test sentiment TH√îNG MINH v·ªõi aspect relevance detection'
    )
    parser.add_argument('--sentence', '-s', type=str, help='C√¢u c·∫ßn test')
    parser.add_argument('--batch', '-b', type=str, 
                       help='File ch·ª©a danh s√°ch c√¢u (m·ªói d√≤ng m·ªôt c√¢u)')
    parser.add_argument('--show-ignored', action='store_true', 
                       help='Hi·ªÉn th·ªã aspects b·ªã ignore')
    parser.add_argument('--evaluate', '-e', type=str,
                       help='ƒê√°nh gi√° model tr√™n t·∫≠p test/validation (CSV file)')
    
    args = parser.parse_args()
    
    if not os.path.exists(MODEL_PATH):
        print(f"\n{Fore.RED}‚ùå Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh t·∫°i: {MODEL_PATH}{Style.RESET_ALL}\n")
        return
    
    # Initialize predictor
    predictor = SmartSentimentPredictor(MODEL_PATH)
    
    # Evaluation mode
    if args.evaluate:
        if not os.path.exists(args.evaluate):
            print(f"\n{Fore.RED}‚ùå Kh√¥ng t√¨m th·∫•y file: {args.evaluate}{Style.RESET_ALL}\n")
            return
        
        evaluate_model(predictor, args.evaluate)
        return
    
    # Batch mode
    if args.batch:
        if not os.path.exists(args.batch):
            print(f"\n{Fore.RED}‚ùå Kh√¥ng t√¨m th·∫•y file: {args.batch}{Style.RESET_ALL}\n")
            return
        
        with open(args.batch, 'r', encoding='utf-8') as f:
            sentences = [line.strip() for line in f if line.strip()]
        
        batch_mode(predictor, sentences)
        return
    
    # Test sentence
    if args.sentence:
        results = predictor.predict_smart(args.sentence)
        print_smart_results(args.sentence, results, show_ignored=args.show_ignored)
        return
    
    # Interactive mode
    interactive_mode(predictor)


if __name__ == '__main__':
    main()
