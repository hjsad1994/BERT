# Cấu hình cho Fine-tuning ViSoBERT ABSA
# ======================================

# Đường dẫn đến dữ liệu và output
paths:
  data_dir: "data"
  train_file: "data/train.csv"
  validation_file: "data/validation.csv"
  test_file: "data/test.csv"
  output_dir: "finetuned_visobert_absa_model"
  evaluation_report: "evaluation_report.txt"
  predictions_file: "test_predictions.csv"

# Cấu hình mô hình
model:
  name: "5CD-AI/Vietnamese-Sentiment-visobert"
  num_labels: 3  # positive, negative, neutral
  max_length: 256  # Độ dài tối đa của input sequence

# Các khía cạnh hợp lệ (dùng để validate dữ liệu)
valid_aspects:
  - Battery
  - Camera
  - Performance
  - Display
  - Design
  - Software
  - Packaging
  - Price
  - Audio
  - Warranty
  - Shop_Service
  - Shipping
  - General
  - Others

# Mapping sentiment: tên nhãn sang ID
sentiment_labels:
  positive: 0
  negative: 1
  neutral: 2

# Tham số huấn luyện
training:
  # Optimizer và learning rate
  learning_rate: 2e-5  # Giảm từ 2.0e-5 để giảm overfitting
  weight_decay: 0.01  # Tăng từ 0.01 để regularization mạnh hơn
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_epsilon: 1.0e-8
  max_grad_norm: 1.0
  
  # Epochs và batch sizes
  num_train_epochs: 4  # Giảm từ 5 → 3 (dựa vào log: epoch 2 best, epoch 4 overfit nặng)
  per_device_train_batch_size: 48  # Train batch size
  per_device_eval_batch_size: 48   # Giảm xuống 24 để tránh crash khi eval/predict
  gradient_accumulation_steps: 1
  
  # Warmup và scheduler
  # warmup_steps: 500
  warmup_ratio: 0.1
  lr_scheduler_type: "linear"
  
  # Evaluation và saving
  evaluation_strategy: "epoch"
  save_strategy: "epoch"
  save_total_limit: 4  # Tăng lên 3 để giữ nhiều checkpoints tốt hơn (an toàn hơn)
  load_best_model_at_end: true  # QUAN TRỌNG: Tự động load best model khi kết thúc
  metric_for_best_model: "eval_f1"  # Chọn checkpoint theo F1 (weighted) - tốt cho imbalanced data
  greater_is_better: true  # F1 cao hơn = tốt hơn
  
  # Early stopping để tránh overfitting
  early_stopping_patience: 2  # Dừng nếu eval_loss không cải thiện sau 2 epoch
  early_stopping_threshold: 0.001  # Ngưỡng cải thiện tối thiểu
  
  # Logging
  logging_strategy: "steps"
  logging_steps: 50
  logging_first_step: true
  
  # Performance optimization
  fp16: true  # RTX 3070 là Ampere, hỗ trợ mixed precision tốt
  fp16_opt_level: "O1"
  dataloader_num_workers: 6  # 8 workers (50% CPU threads, ổn định)
  dataloader_pin_memory: true
  dataloader_prefetch_factor: 12  # Prefetch 8 batches (RAM 32GB → thoải mái)
  dataloader_persistent_workers: true  # Giữ workers sống giữa epochs
  
  # Reproducibility
  seed: 42
  data_seed: 42
  
  # Other training arguments
  disable_tqdm: false
  prediction_loss_only: false
  remove_unused_columns: true
  label_names: ["labels"]

# Tham số chung
general:
  seed: 42
  device: "auto"  # "auto" sẽ tự động chọn GPU nếu có, ngược lại dùng CPU
  log_level: "info"
