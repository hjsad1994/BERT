# Multi-Label Test Scripts

## ğŸ“Š Scripts

### **1. analyze_results.py**

**Purpose:** PhÃ¢n tÃ­ch káº¿t quáº£ chi tiáº¿t theo tá»«ng aspect

**Features:**
- Confusion matrices cho tá»«ng aspect
- Bar charts vá» accuracy, precision, recall, F1
- Heatmap tá»•ng há»£p
- BÃ¡o cÃ¡o chi tiáº¿t dáº¡ng text vÃ  PNG
- Sample distribution analysis

**Usage:**
```bash
# From D:\BERT\
python multi_label\test\analyze_results.py
```

**Requirements:**
- `multi_label/results/test_predictions_multi.csv` (from training)

**Outputs:**
- `multi_label/analysis_results/*.png` (visualizations)
- `multi_label/analysis_results/detailed_analysis_report.txt`

---

### **2. error_analysis.py**

**Purpose:** PhÃ¢n tÃ­ch lá»—i chi tiáº¿t Ä‘á»ƒ tÃ¬m patterns vÃ  cáº£i thiá»‡n

**Features:**
- TÃ¬m cÃ¡c predictions sai
- PhÃ¢n tÃ­ch theo aspect
- PhÃ¢n tÃ­ch theo sentiment
- PhÃ¢n tÃ­ch confusion patterns
- TÃ¬m hard cases
- Äá» xuáº¥t cáº£i thiá»‡n

**Usage:**
```bash
# From D:\BERT\
python multi_label\test\error_analysis.py
```

**Requirements:**
- `multi_label/data/test_multilabel.csv` (ground truth)
- `multi_label/results/test_predictions_multi.csv` (predictions)

**Outputs:**
- `multi_label/error_analysis_results/aspect_error_analysis.csv`
- `multi_label/error_analysis_results/sentiment_error_analysis.csv`
- `multi_label/error_analysis_results/confusion_patterns.csv`
- `multi_label/error_analysis_results/hard_cases.csv`
- `multi_label/error_analysis_results/all_errors_detailed.csv`
- `multi_label/error_analysis_results/improvement_suggestions.txt`
- `multi_label/error_analysis_results/*.png` (visualizations)

---

## ğŸ¯ Typical Workflow

### **After Training:**

**Option 1: Run Both Scripts at Once (Recommended)** ğŸš€
```bash
# From D:\BERT\
bash multi_label/test/run_analysis.sh
```
**This will run both analyze_results.py and error_analysis.py automatically!**

**Option 2: Run Scripts Individually**

1. **Run analyze_results.py:**
   ```bash
   python multi_label\test\analyze_results.py
   ```
   **Get:** Overall metrics, confusion matrices, visualizations

2. **Run error_analysis.py:**
   ```bash
   python multi_label\test\error_analysis.py
   ```
   **Get:** Detailed error analysis, hard cases, improvement suggestions

---

## ğŸ“Š Expected Outputs

### **Analysis Results:**
```
multi_label/analysis_results/
â”œâ”€â”€ confusion_matrices_all_aspects.png
â”œâ”€â”€ confusion_matrix_overall.png
â”œâ”€â”€ metrics_comparison.png
â”œâ”€â”€ accuracy_by_aspect.png
â”œâ”€â”€ f1_score_by_aspect.png
â”œâ”€â”€ precision_by_aspect.png
â”œâ”€â”€ recall_by_aspect.png
â”œâ”€â”€ sample_distribution.png
â”œâ”€â”€ metrics_heatmap.png
â”œâ”€â”€ summary_table.png
â””â”€â”€ detailed_analysis_report.txt
```

### **Error Analysis Results:**
```
multi_label/error_analysis_results/
â”œâ”€â”€ aspect_error_analysis.csv
â”œâ”€â”€ sentiment_error_analysis.csv
â”œâ”€â”€ confusion_patterns.csv
â”œâ”€â”€ hard_cases.csv
â”œâ”€â”€ all_errors_detailed.csv
â”œâ”€â”€ errors_summary_by_aspect.csv
â”œâ”€â”€ improvement_suggestions.txt
â”œâ”€â”€ error_analysis_report.txt
â”œâ”€â”€ aspect_error_rates.png
â”œâ”€â”€ confusion_matrix.png
â””â”€â”€ sentiment_error_rates.png
```

---

## âš™ï¸ Configuration

**Paths are pre-configured for multi-label:**
- Data: `multi_label/data/test_multilabel.csv`
- Predictions: `multi_label/results/test_predictions_multi.csv`
- Analysis output: `multi_label/analysis_results/`
- Error analysis output: `multi_label/error_analysis_results/`

**All paths are relative to project root (D:\BERT\)**

---

## ğŸ” What to Look For

### **In analyze_results.py:**
- Overall F1 score (target: 96%+) ğŸ¯
- Weakest aspects (lowest F1)
- Class imbalance in confusion matrix
- Aspect-wise performance variation

### **In error_analysis.py:**
- Error rate by aspect (target: < 5%)
- Most common confusion pairs
- Hard cases (sentences confused across multiple aspects)
- Improvement suggestions
- Focal Loss + Contrastive Learning effectiveness

---

## ğŸ“ Notes

**Multi-Label Format:**
- Each row is one sentence with ALL 11 aspects
- Labels: 0=positive, 1=negative, 2=neutral
- One row per sentence (all aspects in columns)

**Novel Approach:**
- Using Focal Loss + Contrastive Learning
- Balanced data (15,921 samples)
- Target: 96%+ F1 score

**Run from root:** Always run from `D:\BERT\` directory

**Dependencies:**
- pandas
- numpy
- matplotlib
- seaborn
- scikit-learn

---

## âœ… Quick Test

**Verify scripts work:**
```bash
# From D:\BERT\
python multi_label\test\analyze_results.py
python multi_label\test\error_analysis.py
```

**Expected:** No errors, outputs created in respective folders

---

## ğŸ¯ Performance Comparison

**Expected Results:**

```
Single-Label:  93.31% F1
Multi-Label:   96.0-96.5% F1 (target)

Improvement:   +2.7-3.2%
Method:        Focal Loss + Contrastive Learning
```

**Use these test scripts to verify results after training!** ğŸš€
