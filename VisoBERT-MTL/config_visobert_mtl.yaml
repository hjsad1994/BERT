# ViSoBERT Multi-Task Learning Configuration
# ========================================================================
# Multi-task approach: Train AD and SC simultaneously with shared backbone
# 
# Model: ViSoBERT (Pretrained BERT) with 2 task-specific heads
#   - Shared: ViSoBERT Transformer (110M params)
#   - Head 1: AD (binary focal loss, 11 outputs)
#   - Head 2: SC (focal loss, 11 × 3 outputs)
# 
# Loss: Combined loss = α * Focal_AD + β * Focal_SC
# ========================================================================

paths:
  data_dir: "VisoBERT-STL/data"
  train_file: "VisoBERT-STL/data/train_multilabel.csv"
  validation_file: "VisoBERT-STL/data/validation_multilabel.csv"
  test_file: "VisoBERT-STL/data/test_multilabel.csv"
  output_dir: "VisoBERT-MTL/models/mtl"
  final_results_dir: "VisoBERT-MTL/results"

model:
  # Pretrained ViSoBERT
  name: "5CD-AI/visobert-14gb-corpus"
  
  # Task heads
  hidden_size: 512
  dropout: 0.3
  
  # Task settings
  num_aspects: 11
  num_sentiments: 3
  max_length: 256

aspect_names:
  - Battery
  - Camera
  - Performance
  - Display
  - Design
  - Packaging
  - Price
  - Shop_Service
  - Shipping
  - General
  - Others

sentiment_labels:
  positive: 0
  negative: 1
  neutral: 2

training:
  # Batch sizes (reduced for memory safety)
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 16
  gradient_accumulation_steps: 2
  
  # Optimizer
  learning_rate: 2.0e-5     # Lower for pretrained model
  weight_decay: 0.01
  max_grad_norm: 1.0
  
  # Scheduler
  lr_scheduler_type: "cosine"
  warmup_ratio: 0.06
  
  # Training duration
  num_train_epochs: 10
  
  # Mixed precision
  fp16: true
  
  # DataLoader
  dataloader_num_workers: 2
  dataloader_pin_memory: true
  
  # Evaluation
  evaluation_strategy: "epoch"
  save_strategy: "epoch"
  save_total_limit: 3
  
  # Early stopping
  early_stopping_patience: 5
  early_stopping_threshold: 0.001
  
  # Logging
  logging_steps: 50
  
  # Device
  device: "cuda"

# Multi-task learning settings
multi_task:
  # Loss weights (combined loss = alpha * Focal_AD + beta * Focal_SC)
  # Using 0.3:0.7 ratio from old train_multitask.py (total=1.0, SC-focused)
  loss_weight_ad: 0.3       # Weight for AD focal loss (30%)
  loss_weight_sc: 0.7       # Weight for SC focal loss (70%)
  
  # AD task settings
  aspect_detection:
    use_focal_loss: true
    focal_gamma: 2.0
    focal_alpha: "auto"     # Auto-calculate from data (inverse frequency)
    metric: "f1_macro"
  
  # SC task settings
  sentiment_classification:
    use_focal_loss: true
    focal_gamma: 2.0
    focal_alpha: "auto"     # Auto-calculate from data (global distribution)
    metric: "f1_macro"      # Changed to F1 Macro (standard in ABSA research)
  
  # Best model selection
  # Options: "ad_f1", "sc_f1", "combined_f1" (average of AD/SC F1)
  best_model_metric: "combined_f1"

# Reproducibility
reproducibility:
  seed: 42
  deterministic: true

general:
  log_level: "info"
  save_predictions: true
