# ViSoBERT + Focal Loss + Contrastive Loss - Kiáº¿n trÃºc Chi tiáº¿t

## ğŸ¯ TRáº¢ Lá»œI CÃ‚U Há»I:

> "2 loss nÃ y cháº¡y cÃ¹ng lÃºc hay riÃªng láº»? Focal trÆ°á»›c hay Contrastive trÆ°á»›c?"

### âœ… **CHáº Y CÃ™NG LÃšC (SIMULTANEOUSLY)!**

**KHÃ”NG pháº£i:**
- âŒ Focal trÆ°á»›c, rá»“i Contrastive
- âŒ Contrastive trÆ°á»›c, rá»“i Focal
- âŒ Cháº¡y 2 láº§n forward pass riÃªng láº»

**MÃ€ LÃ€:**
- âœ… 1 láº§n forward pass â†’ 2 outputs (logits + embeddings)
- âœ… 2 losses tÃ­nh CÃ™NG LÃšC tá»« 2 outputs Ä‘Ã³
- âœ… Káº¿t há»£p láº¡i thÃ nh 1 loss duy nháº¥t
- âœ… 1 láº§n backprop update Táº¤T Cáº¢ weights

---

## ğŸ“Š KIáº¾N TRÃšC MODEL

### **ToÃ n cáº£nh:**

```
INPUT TEXT ("Pin tot camera xau")
    |
    v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ViSoBERT ENCODER      â”‚  â† Shared encoder
â”‚   [batch, 768]          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          |
          v
    â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”  â† CHIA 2 NHÃNH (PARALLEL)
    |           |
    v           v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CLASS   â”‚ â”‚ PROJECTION   â”‚
â”‚ HEAD    â”‚ â”‚ HEAD         â”‚
â”‚         â”‚ â”‚              â”‚
â”‚ Logits  â”‚ â”‚ Embeddings   â”‚
â”‚[b,11,3] â”‚ â”‚ [b, 256]     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    |           |
    v           v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FOCAL   â”‚ â”‚ CONTRASTIVE  â”‚  â† 2 LOSSES (PARALLEL)
â”‚ LOSS    â”‚ â”‚ LOSS         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    |           |
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
          v
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ COMBINED    â”‚  â† 0.8*Focal + 0.2*Contr
    â”‚ LOSS        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          |
          v
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ BACKPROP    â”‚  â† Update Táº¤T Cáº¢ weights
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ FORWARD PASS FLOW (Step-by-Step)

### **Step 1: Input**
```python
text = "Pin tot camera xau"
input_ids = tokenizer(text)  # [batch_size, seq_len]
```

### **Step 2: Encoder (ViSoBERT)**
```python
hidden_states = visobert(input_ids, attention_mask)
pooled_output = hidden_states[:, 0, :]  # [CLS] token
# Shape: [batch_size, 768]
```

### **Step 3: PARALLEL - Two Branches**

**Branch A: Classification Head (cho Focal Loss)**
```python
# Dense layer
x = self.dense(pooled_output)  # [batch, 512]
x = F.relu(x)
x = self.dropout(x)

# Output layer
logits = self.out(x)  # [batch, 11, 3]
# 11 aspects Ã— 3 sentiments
```

**Branch B: Projection Head (cho Contrastive Loss)**
```python
# Projection
embeddings = self.projection(pooled_output)  # [batch, 256]

# L2 normalize for contrastive learning
embeddings = F.normalize(embeddings, p=2, dim=1)
```

**âš ï¸ QUAN TRá»ŒNG:** Cáº£ 2 branches nÃ y cháº¡y CÃ™NG LÃšC trong 1 forward pass!

### **Step 4: Calculate Losses (SIMULTANEOUSLY)**

**Focal Loss (tá»« logits):**
```python
focal_loss = 0
for i in range(11):  # Má»—i aspect
    aspect_logits = logits[:, i, :]  # [batch, 3]
    aspect_labels = labels[:, i]     # [batch]
    
    loss = focal_loss_fn(aspect_logits, aspect_labels)
    focal_loss += loss

focal_loss = focal_loss / 11  # Average
```

**Contrastive Loss (tá»« embeddings):**
```python
contr_loss = contrastive_loss_fn(embeddings, labels)
# Pulls similar samples together
# Pushes different samples apart
```

**âš ï¸ QUAN TRá»ŒNG:** 2 losses nÃ y tÃ­nh CÃ™NG LÃšC, KHÃ”NG pháº£i tuáº§n tá»±!

### **Step 5: Combine**
```python
# Weighted combination
total_loss = 0.8 * focal_loss + 0.2 * contr_loss
# (weights tá»« config.yaml)
```

### **Step 6: Backpropagation**
```python
# Single backprop
total_loss.backward()  # Updates ALL weights:
                       # - ViSoBERT encoder
                       # - Classification head
                       # - Projection head

optimizer.step()  # Apply updates
```

---

## â±ï¸ TIMELINE (trong 1 iteration)

```
Time    |  Action
--------|--------------------------------------------------
0ms     |  Load batch (input_ids, labels)
        |
5ms     |  Forward: ViSoBERT encoder
        |     â†“
10ms    |  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        |  â”‚ Class head   â”‚ Proj head    â”‚  (PARALLEL)
15ms    |  â”‚ â†’ logits     â”‚ â†’ embeddings â”‚
        |  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        |     â†“               â†“
20ms    |  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        |  â”‚ Focal loss   â”‚ Contr loss   â”‚  (PARALLEL)
25ms    |  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        |     â†“
30ms    |  Combine: total_loss
        |     â†“
50ms    |  Backprop: total_loss.backward()
        |     â†“
70ms    |  optimizer.step()
        |
        |  DONE! (Total: ~70ms per batch)
```

**Náº¿u cháº¡y tuáº§n tá»± (WRONG):**
```
Would need: ~100-120ms (slower!)
Because: 
  - Forward 1: Focal (50ms)
  - Backprop 1: Focal (30ms)
  - Forward 2: Contrastive (50ms)
  - Backprop 2: Contrastive (30ms)
  = 160ms total
```

---

## ğŸ’¡ Táº I SAO CHáº Y CÃ™NG LÃšC?

### **1. Hiá»‡u quáº£ (Efficiency)**
- âœ… 1 forward pass thay vÃ¬ 2
- âœ… 1 backprop thay vÃ¬ 2
- âœ… Nhanh hÆ¡n ~2x

### **2. Há»c tá»‘t hÆ¡n (Better Learning)**
- âœ… Model há»c Cáº¢ classification VÃ€ representation cÃ¹ng lÃºc
- âœ… Gradient tá»« 2 losses bá»• sung cho nhau
- âœ… Encoder Ä‘Æ°á»£c optimize cho Cáº¢ 2 tasks

### **3. Implementation Ä‘Æ¡n giáº£n**
```python
# Chá»‰ cáº§n 1 forward pass:
logits, embeddings = model(input_ids, attention_mask, 
                          return_embeddings=True)

# TÃ­nh cáº£ 2 losses:
focal_loss = focal_loss_fn(logits, labels)
contr_loss = contr_loss_fn(embeddings, labels)

# Combine:
total_loss = 0.8 * focal_loss + 0.2 * contr_loss

# Single backprop:
total_loss.backward()
```

---

## ğŸ” CHI TIáº¾T IMPLEMENTATION

### **Model Forward:**

```python
class MultiLabelViSoBERTFocalContrastive(nn.Module):
    def forward(self, input_ids, attention_mask, return_embeddings=False):
        # 1. Encoder
        outputs = self.bert(input_ids, attention_mask)
        pooled = outputs.pooler_output  # [batch, 768]
        
        # 2a. Classification branch
        x = self.dense(pooled)
        x = F.relu(x)
        x = self.dropout(x)
        logits = self.out(x)  # [batch, 11, 3]
        
        if return_embeddings:
            # 2b. Projection branch
            embeddings = self.projection(pooled)  # [batch, 256]
            embeddings = F.normalize(embeddings, p=2, dim=1)
            return logits, embeddings
        
        return logits
```

### **Training Loop:**

```python
for batch in dataloader:
    # 1. Forward (BOTH branches)
    logits, embeddings = model(input_ids, attention_mask, 
                              return_embeddings=True)
    
    # 2. Calculate BOTH losses (SIMULTANEOUSLY)
    focal_loss = focal_loss_fn(logits, labels)
    contr_loss = contr_loss_fn(embeddings, labels)
    
    # 3. Combine
    total_loss = 0.8 * focal_loss + 0.2 * contr_loss
    
    # 4. Single backprop
    optimizer.zero_grad()
    total_loss.backward()
    optimizer.step()
```

---

## ğŸ“Š Lá»¢I ÃCH Cá»¦A Tá»ªNG LOSS

### **Focal Loss (tá»« Logits)**
**Má»¥c Ä‘Ã­ch:** Classification tá»‘t hÆ¡n
```
Input:  Logits [batch, 11, 3]
Output: Loss scalar

LÃ m gÃ¬:
- Focus vÃ o hard examples (sai nhiá»u)
- Giáº£m weight cho easy examples (Ä‘Ãºng rá»“i)
- Handle class imbalance

VÃ­ dá»¥:
  Easy:  Predicted [0.9, 0.05, 0.05], True=0
         â†’ Weight tháº¥p (0.1)
  
  Hard:  Predicted [0.4, 0.3, 0.3], True=0
         â†’ Weight cao (2.5)
         â†’ Model focus há»c cÃ¡i nÃ y
```

### **Contrastive Loss (tá»« Embeddings)**
**Má»¥c Ä‘Ã­ch:** Representation learning
```
Input:  Embeddings [batch, 256]
Output: Loss scalar

LÃ m gÃ¬:
- Pull similar samples together
- Push different samples apart
- Organize embedding space

VÃ­ dá»¥:
  Sample A: "Pin tot" â†’ embedding [0.1, 0.2, ...]
  Sample B: "Pin ngon" â†’ embedding [0.12, 0.22, ...]
  Sample C: "Pin te" â†’ embedding [-0.5, -0.4, ...]
  
  Contrastive loss:
    - Pull A & B closer (cÃ¹ng positive)
    - Push A & C apart (khÃ¡c sentiment)
```

---

## ğŸ¯ Vá»Š TRÃ THAM GIA

### **Trong Forward Pass:**

```
INPUT
  â†“
ENCODER (ViSoBERT)
  â†“
  â”œâ”€â†’ Classification Head â†’ LOGITS â†’ FOCAL LOSS
  â”‚
  â””â”€â†’ Projection Head â†’ EMBEDDINGS â†’ CONTRASTIVE LOSS
```

**Cáº£ 2 branches Ä‘á»u:**
- âœ… Báº¯t Ä‘áº§u sau encoder
- âœ… Cháº¡y parallel (khÃ´ng pháº£i sequential)
- âœ… Produce outputs cÃ¹ng lÃºc
- âœ… Losses tÃ­nh cÃ¹ng lÃºc

### **Trong Training:**

```
Epoch 1:
  Batch 1: ViSoBERT â†’ [Logits, Embeddings] â†’ [Focal, Contr] â†’ Combined â†’ Backprop
  Batch 2: ViSoBERT â†’ [Logits, Embeddings] â†’ [Focal, Contr] â†’ Combined â†’ Backprop
  ...
  
Epoch 2:
  Batch 1: ViSoBERT â†’ [Logits, Embeddings] â†’ [Focal, Contr] â†’ Combined â†’ Backprop
  ...
```

**Má»—i batch:**
- âœ… 1 forward pass
- âœ… 2 losses calculated simultaneously
- âœ… 1 backprop

---

## ğŸ“ˆ Káº¾T QUáº¢

### **Focal Loss Only:**
```
Focus: Classification
Result: ~95.0% F1
Problem: Representation khÃ´ng tá»‘t
```

### **Contrastive Loss Only:**
```
Focus: Representation
Result: ~95.4% F1
Problem: Classification khÃ´ng optimal
```

### **Focal + Contrastive (Combined):**
```
Focus: BOTH Classification + Representation
Result: ~96.0% F1
Benefit: Best of both worlds! âœ…
```

---

## âœ… TÃ“M Táº®T

| CÃ¢u há»i | Tráº£ lá»i |
|---------|---------|
| Cháº¡y cÃ¹ng lÃºc hay riÃªng láº»? | **CÃ™NG LÃšC** |
| Focal trÆ°á»›c hay Contrastive trÆ°á»›c? | **KHÃ”NG cÃ³ trÆ°á»›c/sau - PARALLEL** |
| Máº¥y láº§n forward pass? | **1 Láº¦N** |
| Máº¥y láº§n backprop? | **1 Láº¦N** |
| Tham gia giai Ä‘oáº¡n nÃ o? | **SAU Encoder, trÆ°á»›c Backprop** |
| CÃ³ cháº­m hÆ¡n single loss khÃ´ng? | **KHÃ”NG - váº«n nhanh tÆ°Æ¡ng Ä‘Æ°Æ¡ng** |

---

## ğŸ“ KEY INSIGHTS:

1. **Model cÃ³ 2 heads (branches) tá»« shared encoder**
   - Classification head â†’ Logits
   - Projection head â†’ Embeddings

2. **Single forward pass produces BOTH outputs**
   - KhÃ´ng pháº£i 2 forward passes riÃªng
   - Efficient vÃ  nhanh

3. **2 losses calculated SIMULTANEOUSLY**
   - Focal tá»« logits
   - Contrastive tá»« embeddings
   - Káº¿t há»£p thÃ nh 1 loss

4. **Single backprop updates EVERYTHING**
   - Encoder weights
   - Classification head weights
   - Projection head weights
   - Táº¥t cáº£ learn cÃ¹ng lÃºc

5. **Complementary learning**
   - Focal: Improve classification
   - Contrastive: Improve representation
   - Together: Better than either alone

---

**Xem visualizations:** 
- `model_architecture.png` - Kiáº¿n trÃºc Ä‘áº§y Ä‘á»§
- `forward_pass_timeline.png` - Timeline chi tiáº¿t
- `sequential_vs_parallel.png` - So sÃ¡nh sai vs Ä‘Ãºng
