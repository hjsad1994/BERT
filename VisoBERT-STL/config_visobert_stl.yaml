# Sequential Single-Task Learning Configuration for ABSA
# ========================================================================
# Two-stage training approach:
#   Stage 1 (AD): Aspect Detection - Binary classification for 11 aspects (includes Others)
#   Stage 2 (SC): Sentiment Classification - 3-class for 10 aspects (excludes Others)
# 
# Base Model: 5CD-AI/visobert-14gb-corpus
# - General Vietnamese language model (pretrained on ~14GB corpus)
# - Stage 1: 11 binary outputs (aspect mentioned or not, including Others)
# - Stage 2: 10 × 3 multi-class outputs (positive/negative/neutral per aspect, excluding Others)
# - Note: "Others" is detected in AD stage but excluded from SC stage (no sentiment labels)
# ========================================================================

paths:
  # Stage 1: Aspect Detection data files
  ad_train_file: "VisoBERT-STL/data/train_multilabel.csv"
  # ad_train_file: "VisoBERT-STL/data/train_multilabel_ad_balanced_aggressive.csv"
  ad_validation_file: "VisoBERT-STL/data/validation_multilabel.csv"
  ad_test_file: "VisoBERT-STL/data/test_multilabel.csv"
  
  # Stage 2: Sentiment Classification data files
  # sc_train_file: "VisoBERT-STL/data/train_multilabel_balanced.csv"  # Oversampling causes overfitting (Val 94.94% vs Test 91.32%)
  sc_train_file: "VisoBERT-STL/data/train_multilabel.csv"  # NO OVERSAMPLING - better generalization (Test 92.81%)
  sc_validation_file: "VisoBERT-STL/data/validation_multilabel.csv"
  sc_test_file: "VisoBERT-STL/data/test_multilabel.csv"
  
  # Stage 1: Aspect Detection output
  ad_output_dir: "VisoBERT-STL/models/aspect_detection"
  
  # Stage 2: Sentiment Classification output
  sc_output_dir: "VisoBERT-STL/models/sentiment_classification"
  
  # Final results
  final_results_dir: "VisoBERT-STL/results/two_stage_training"

model:
  name: "5CD-AI/visobert-14gb-corpus"  # General Vietnamese model; we fine-tune for multi-label ABSA
  # Note: This base model is not sentiment-specific; fine-tuning handles aspect+sentiment outputs
  # AD stage: 11 aspects (including Others)
  # SC stage: 10 aspects (excluding Others), 10 × 3 = 30 outputs
  max_length: 256
  
  # Model architecture
  hidden_size: 512      # Dense layer
  dropout: 0.3          # Standard dropout

sentiment_labels:
  positive: 0
  negative: 1
  neutral: 2

training:
  # Batch size
  per_device_train_batch_size: 16
  per_device_eval_batch_size: 32
  
  # Optimizer settings
  learning_rate: 2.0e-5
  weight_decay: 0.01    # Standard weight decay
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_epsilon: 1.0e-8
  max_grad_norm: 1.0
  
  # DataLoader settings
  dataloader_num_workers: 2  # Reduced for larger batches
  dataloader_pin_memory: true
  dataloader_prefetch_factor: 4
  dataloader_persistent_workers: true

reproducibility:
  training_seed: 100                # Seed for PyTorch/Transformers training

# Sequential training settings
two_stage:
  # Training order
  train_ad_first: true      # Train Aspect Detection before Sentiment Classification
  train_sc_after: true      # Train Sentiment Classification after AD
  
  # Stage 1: Aspect Detection
  aspect_detection:
    use_focal_loss: true
    focal_gamma: 2.0
    focal_alpha: "auto"     # Auto-calculate from data (inverse frequency)
    epochs: 12               # AD training epochs
    warmup_ratio: 0.08      # Warmup ratio for AD stage (8% - higher for non-oversampled data)
    early_stopping_patience: 2  # Patience for AD stage
    early_stopping_threshold: 0.0005  # Minimum improvement threshold (0.05% F1)
  
  # Stage 2: Sentiment Classification
  sentiment_classification:
    use_focal_loss: true
    focal_gamma: 2.0        # Increased from 2.0 → 3.0 to focus on hard samples # best 1.3 for old data
    focal_alpha: "auto"     # Auto-calculate from data
    epochs: 12              # Standard epochs for non-oversampled data
    warmup_ratio: 0.06      # Warmup ratio for SC stage
    early_stopping_patience: 2  # Patience for SC stage
    early_stopping_threshold: 0.0005  # Minimum improvement threshold (0.05% F1)
  
  # Error analysis
  run_error_analysis: true  # Automatically run error analysis after training