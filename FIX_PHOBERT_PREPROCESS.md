# üîß Fix PhoBERT preprocess_data.py

## ‚ùå Error

```
KeyError: 'sentence'
```

**Nguy√™n nh√¢n**: 
- Script expect column `'sentence'` 
- Dataset c√≥ column `'data'`

---

## ‚úÖ Solution

### Option 1: Fix Script (Quick)

Open `E:\ABSA-PhoBERT\multi-label\preprocess_data.py` v√† t√¨m d√≤ng:

```python
result_df['sentence'] = df['sentence']  # Line 58
```

**S·ª≠a th√†nh**:
```python
result_df['sentence'] = df['data']  # Use 'data' column instead
```

---

### Option 2: Copy Updated Script from D:\BERT

B·∫°n c√≥ script ƒë√£ update ·ªü `D:\BERT\single_label\preprocess_data.py` v·ªõi stratified split.

**Copy sang PhoBERT project**:

```bash
# Copy script
cp D:\BERT\single_label\preprocess_data.py E:\ABSA-PhoBERT\multi-label\

# Ho·∫∑c d√πng PowerShell
Copy-Item "D:\BERT\single_label\preprocess_data.py" -Destination "E:\ABSA-PhoBERT\multi-label\"
```

**R·ªìi ch·∫°y**:
```bash
cd E:\ABSA-PhoBERT
python multi-label\preprocess_data.py --config multi-label\config.yaml
```

---

## üéØ Recommended: Use Correct Script

Dataset c·ªßa b·∫°n format:
```csv
data,Battery,Camera,Performance,...
"Pin t·ªët camera k√©m",Positive,Negative,...
```

‚Üí ƒê√¢y l√† **MULTI-LABEL format** (1 row per review)

**Script c·∫ßn**:
- Input: `dataset.csv` with column `'data'`
- Keep multi-label format (kh√¥ng convert sang single-label)
- Split with stratification

---

## üìù Full Fix Script

T√¥i t·∫°o script m·ªõi ƒë√∫ng cho b·∫°n:

```python
"""
Multi-Label Data Preprocessing for PhoBERT ABSA
Keeps multi-label format: 1 row per review with all aspects
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import os
import yaml

def load_config(config_path='config.yaml'):
    with open(config_path, 'r') as f:
        return yaml.safe_load(f)

def main():
    # Load config
    config = load_config()
    seed = config['reproducibility']['data_split_seed']
    
    print("="*60)
    print("Multi-Label Data Preprocessing")
    print("="*60)
    print(f"Seed: {seed}")
    
    # Load dataset
    print("\n1. Loading dataset...")
    df = pd.read_csv('dataset.csv', encoding='utf-8-sig')
    print(f"   Loaded: {len(df)} reviews")
    
    # Verify columns
    expected_cols = ['data', 'Battery', 'Camera', 'Performance', 
                     'Display', 'Design', 'Packaging', 'Price',
                     'Shop_Service', 'Shipping', 'General', 'Others']
    
    missing = [col for col in expected_cols if col not in df.columns]
    if missing:
        raise ValueError(f"Missing columns: {missing}")
    
    print(f"   ‚úì All columns present")
    
    # Sort for reproducibility across machines
    print("\n2. Sorting data for reproducibility...")
    df = df.sort_values(by=['data', 'Battery', 'Camera'], ignore_index=True)
    print(f"   ‚úì Data sorted")
    
    # Split with stratification
    print("\n3. Splitting data (stratified)...")
    
    # Create stratify label (dominant sentiment)
    def get_dominant_sentiment(row):
        sentiments = []
        for col in expected_cols[1:]:  # Skip 'data'
            if pd.notna(row[col]) and str(row[col]).strip() != '':
                sentiments.append(str(row[col]).strip())
        
        if not sentiments:
            return 'neutral'
        
        from collections import Counter
        counter = Counter(sentiments)
        return counter.most_common(1)[0][0]
    
    df['stratify_temp'] = df.apply(get_dominant_sentiment, axis=1)
    
    # Split: train+val vs test
    train_val_df, test_df = train_test_split(
        df,
        test_size=0.1,
        random_state=seed,
        stratify=df['stratify_temp'],
        shuffle=True
    )
    
    # Split: train vs val
    train_df, val_df = train_test_split(
        train_val_df,
        test_size=0.11,  # 10% of total (10/90)
        random_state=seed,
        stratify=train_val_df['stratify_temp'],
        shuffle=True
    )
    
    # Remove stratify column
    train_df = train_df.drop('stratify_temp', axis=1)
    val_df = val_df.drop('stratify_temp', axis=1)
    test_df = test_df.drop('stratify_temp', axis=1)
    
    print(f"   Train: {len(train_df)} ({len(train_df)/len(df)*100:.1f}%)")
    print(f"   Val:   {len(val_df)} ({len(val_df)/len(df)*100:.1f}%)")
    print(f"   Test:  {len(test_df)} ({len(test_df)/len(df)*100:.1f}%)")
    
    # Save
    print("\n4. Saving splits...")
    os.makedirs('data', exist_ok=True)
    
    train_df.to_csv('data/train.csv', index=False, encoding='utf-8-sig')
    val_df.to_csv('data/validation.csv', index=False, encoding='utf-8-sig')
    test_df.to_csv('data/test.csv', index=False, encoding='utf-8-sig')
    
    print(f"   ‚úì Saved to data/ folder")
    
    print("\n‚úì Complete!")

if __name__ == '__main__':
    main()
```

**L∆∞u script n√†y v√†o**: `E:\ABSA-PhoBERT\multi-label\preprocess_data_fixed.py`

**Ch·∫°y**:
```bash
cd E:\ABSA-PhoBERT
python multi-label\preprocess_data_fixed.py
```

---

## üéØ Summary

**L·ªói**: Script expect `'sentence'` column, dataset c√≥ `'data'` column

**Fix**:
1. **Quick**: S·ª≠a line 58: `df['sentence']` ‚Üí `df['data']`
2. **Better**: Copy script updated t·ª´ D:\BERT
3. **Best**: D√πng script fixed ·ªü tr√™n (c√≥ stratification + sorting)

---

**B·∫°n mu·ªën t√¥i t·∫°o full script m·ªõi kh√¥ng?**
